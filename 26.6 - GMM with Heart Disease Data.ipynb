{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Apply GMM to the heart disease data by setting n_components=2. Get ARI and silhoutte scores for your solution and compare it with those of the k-means and hierarchical clustering solutions that you implemented in the assignments of the previous checkpoints. Which algorithm does perform better?\n",
    "\n",
    "2. GMM implementation of scikit-learn has a parameter called covariance_type. This parameter determines the type of covariance parameters to use. Specifically, there are four types you can specify:\n",
    "\n",
    " - full: This is the default. Each component has its own general covariance matrix.\n",
    " - tied: All components share the same general covariance matrix.\n",
    " - diag: Each component has its own diagonal covariance matrix.\n",
    " - spherical: Each component has its own single variance.\n",
    "\n",
    "Try all of these. Which one does perform better in terms of ARI and silhouette scores?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Ellipse\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import datasets, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "postgres_user = 'dsbc_student'\n",
    "postgres_pw = '7*.8G9QH21'\n",
    "postgres_host = '142.93.121.174'\n",
    "postgres_port = '5432'\n",
    "postgres_db = 'heartdisease'\n",
    "\n",
    "engine = create_engine('postgresql://{}:{}@{}:{}/{}'.format(\n",
    "    postgres_user, postgres_pw, postgres_host, postgres_port, postgres_db))\n",
    "heartdisease_df = pd.read_sql_query('select * from heartdisease',con=engine)\n",
    "\n",
    "# no need for an open connection, as we're only doing a single query\n",
    "engine.dispose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the features and the outcome\n",
    "X = heartdisease_df.iloc[:, :13]\n",
    "y = heartdisease_df.iloc[:, 13]\n",
    "\n",
    "# Replace missing values (marked by ?) with a 0\n",
    "X = X.replace(to_replace='?', value=0)\n",
    "\n",
    "# Binarize y so that 1 means heart disease diagnosis and 0 means no diagnosis\n",
    "y = np.where(y > 0, 0, 1)\n",
    "\n",
    "# Standarizing the features\n",
    "scaler = StandardScaler()\n",
    "X_std = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Apply GMM to the heart disease data by setting n_components=2. Get ARI and silhoutte scores for your solution and compare it with those of the k-means and hierarchical clustering solutions that you implemented in the assignments of the previous checkpoints. Which algorithm does perform better?\n",
    "\n",
    "K-means clearly performs better with the largest ARI and silhouette scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the agglomerative clustering\n",
    "gmm_cluster = GaussianMixture(n_components=2, random_state=123)\n",
    "agg_cluster = AgglomerativeClustering(linkage='average', \n",
    "                                      affinity='cosine',\n",
    "                                      n_clusters=2)\n",
    "k_cluster = KMeans(n_clusters=2, random_state=123)\n",
    "\n",
    "# Fit model\n",
    "gmm_clusters = gmm_cluster.fit_predict(X_std)\n",
    "agg_clusters = agg_cluster.fit_predict(X_std)\n",
    "k_clusters = k_cluster.fit_predict(X_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ARI score for GMM algorithm:  0.18389186035089963\n",
      "Silhouette score for GMM algorithm:  0.13628813153331445\n",
      "\n",
      "\n",
      "ARI score for k-means algorithm:  0.4380857727169879\n",
      "Silhouette score for k-means algorithm:  0.17530682286260937\n",
      "\n",
      "\n",
      "ARI score for hierarchical algorithm:  0.2940490133353465\n",
      "Silhouette score for hierarchical algorithm:  0.14837359969689895\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('ARI score for GMM algorithm: ', metrics.adjusted_rand_score(y, gmm_clusters))\n",
    "print('Silhouette score for GMM algorithm: ', metrics.silhouette_score(X_std, gmm_clusters, metric='euclidean'))\n",
    "print('\\n')\n",
    "print('ARI score for k-means algorithm: ', metrics.adjusted_rand_score(y, k_clusters))\n",
    "print('Silhouette score for k-means algorithm: ', metrics.silhouette_score(X_std, k_clusters, metric='euclidean'))\n",
    "print('\\n')\n",
    "print('ARI score for hierarchical algorithm: ', metrics.adjusted_rand_score(y, agg_clusters))\n",
    "print('Silhouette score for hierarchical algorithm: ', metrics.silhouette_score(X_std, agg_clusters, metric='euclidean'))\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. GMM implementation of scikit-learn has a parameter called covariance_type. This parameter determines the type of covariance parameters to use. Specifically, there are four types you can specify:\n",
    "\n",
    " - full: This is the default. Each component has its own general covariance matrix.\n",
    " - tied: All components share the same general covariance matrix.\n",
    " - diag: Each component has its own diagonal covariance matrix.\n",
    " - spherical: Each component has its own single variance.\n",
    "\n",
    "Try all of these. Which one does perform better in terms of ARI and silhouette scores?\n",
    "\n",
    "The full, tied, and diag models are all the same. The model with spherical covariance has a higher ARI score and lower silhouette score than the others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the agglomerative clustering\n",
    "full_cluster = GaussianMixture(n_components=2, random_state=123, covariance_type='full')\n",
    "tied_cluster = GaussianMixture(n_components=2, random_state=123, covariance_type='tied')\n",
    "diag_cluster = GaussianMixture(n_components=2, random_state=123, covariance_type='diag')\n",
    "spherical_cluster = GaussianMixture(n_components=2, random_state=123, covariance_type='spherical')\n",
    "\n",
    "# Fit model\n",
    "full_clusters = full_cluster.fit_predict(X_std)\n",
    "tied_clusters = tied_cluster.fit_predict(X_std)\n",
    "diag_clusters = diag_cluster.fit_predict(X_std)\n",
    "spherical_clusters = spherical_cluster.fit_predict(X_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ARI score for full covariance:  0.18389186035089963\n",
      "Silhouette score for full covariance:  0.13628813153331445\n",
      "\n",
      "\n",
      "ARI score for tied covariance:  0.18389186035089963\n",
      "Silhouette score for tied covariance:  0.13628813153331445\n",
      "\n",
      "\n",
      "ARI score for diag covariance:  0.18389186035089963\n",
      "Silhouette score for diag covariance:  0.13628813153331445\n",
      "\n",
      "\n",
      "ARI score for spherical covariance:  0.20765243525722465\n",
      "Silhouette score for spherical covariance:  0.12468753110276873\n"
     ]
    }
   ],
   "source": [
    "print('ARI score for full covariance: ', metrics.adjusted_rand_score(y, full_clusters))\n",
    "print('Silhouette score for full covariance: ', metrics.silhouette_score(X_std, full_clusters, metric='euclidean'))\n",
    "print('\\n')\n",
    "print('ARI score for tied covariance: ', metrics.adjusted_rand_score(y, tied_clusters))\n",
    "print('Silhouette score for tied covariance: ', metrics.silhouette_score(X_std, tied_clusters, metric='euclidean'))\n",
    "print('\\n')\n",
    "print('ARI score for diag covariance: ', metrics.adjusted_rand_score(y, diag_clusters))\n",
    "print('Silhouette score for diag covariance: ', metrics.silhouette_score(X_std, diag_clusters, metric='euclidean'))\n",
    "print('\\n')\n",
    "print('ARI score for spherical covariance: ', metrics.adjusted_rand_score(y, spherical_clusters))\n",
    "print('Silhouette score for spherical covariance: ', metrics.silhouette_score(X_std, spherical_clusters, metric='euclidean'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
