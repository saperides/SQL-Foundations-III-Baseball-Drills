{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'python3' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-3f635663dc27>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpython3\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mversion\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'python3' is not defined"
     ]
    }
   ],
   "source": [
    "python3 --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pip3' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-8fa0e15ea08f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpip3\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mversion\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'pip3' is not defined"
     ]
    }
   ],
   "source": [
    "pip3 --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'virtualenv' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-1fef3fe82ef3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mvirtualenv\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mversion\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'virtualenv' is not defined"
     ]
    }
   ],
   "source": [
    "virtualenv --version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checkpoint 2 - History of ANN\n",
    "A long long time ago, in a galaxy that was actually this same galaxy, people started building artificial neural networks. Artificial Neural Networks (ANN) were, somewhat unsurprisingly, born of a desire to simulate neural networks in the brain. This work really began in the 1950s, and while it is now considered a significant development in computer science, it wasn't really seen to be that at the time.\n",
    "\n",
    "In fact, while there were some significant developments along the way, Neural Networks faded from the general consciousness. In fact, a now very popular lecture from MIT on neural networks acknowledges that they were almost scrapped from the curriculum on Machine Learning at the school (you can see that lecture here). It may seem extreme now, but that was the reality a little over a decade ago. Neural Networks were ineffective and inefficient.\n",
    "\n",
    "Now, of course, ANN has become one of the most exciting and influential facets of machine learning. Deep Learning is one of the most in-demand skills in the world today, based entirely on ANN as a framework.\n",
    "\n",
    "So, how did this happen?\n",
    "\n",
    "### The Rebirth of Neural Networks\n",
    "Most people would point to 2006 as the year that the rebirth of Neural Networks started to regain traction.\n",
    "\n",
    "There was a series of machine learning teams starting to win several competitions (think an older, more exclusive version of Kaggle) with neural networks. A particularly famous team of researchers from this period were led by Jurgen Schmidhuber out of a lab in Switzerland called IDSIA. As what are now called neural networks started winning competition after competition, people started to take notice.\n",
    "\n",
    "At the time, ANNs were being used as an unsupervised technique. As computational power continued to develop, however, they also became relevant for supervised learning problems. Some people started to develop ways to run these algorithms even more efficiently using things like GPUs, or Graphics Processing Units, which are highly parallelizable and allowed for these systems to get even more complex.\n",
    "\n",
    "To this point, however, coding up a neural network required a lot of manual development of algorithms. This limited their impact to only the most technical projects in the machine learning world.\n",
    "\n",
    "That would soon change.\n",
    "\n",
    "### New Tools\n",
    "As with many open source tools in the past decade or so, our story now has to turn to Google. In around 2011, a team at Google started working on a tool called DistBelief. This was a key part of Google Brain, one of Googleâ€™s earlier Artificial Intelligence projects, and became the back end for several different internal projects.\n",
    "\n",
    "When DistBelief became more and more impactful, Google chose to make it open source in 2015 in a new iteration, now known as TensorFlow. TensorFlow is a robust tool set for building a variety of models, but it is particularly useful for neural networks.\n",
    "\n",
    "Initially, TensorFlow was relatively complex to use, requiring quite a bit of expertise. Elsewhere, a tool called Keras was developed as a way of making the process of creating a neural network easier out of the box. It sat on top of TensorFlow (or another similar neural network package we're not going to cover here called Theano) and made it so you could make a fully functional neural network in just a few lines of code, emphasizing usability without sacrificing robustness.\n",
    "\n",
    "Then, even more recently, Keras and TensorFlow integrated, allowing you to use Keras natively with TensorFlow, making modeling even easier. This is a huge part of what has led to the popularity of neural networks as a modeling framework and even Python as a language for data science.\n",
    "\n",
    "When building a bespoke neural network, we recommend using Keras. That said, to really understand how it works you're going to need to know more about TensorFlow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checkpoint 3 - How TensorFlow Works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.7.4 (default, Aug  9 2019, 18:34:13) [MSC v.1915 64 bit (AMD64)]\n",
      "\n",
      "Please wait a moment while I gather a list of all available modules...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\kernel\\__init__.py:13: ShimWarning: The `IPython.kernel` package has been deprecated since IPython 4.0.You should import from ipykernel or jupyter_client instead.\n",
      "  \"You should import from ipykernel or jupyter_client instead.\", ShimWarning)\n",
      "WARNING: AstropyDeprecationWarning: astropy.utils.compat.futures is now deprecated - use concurrent.futures instead [astropy.utils.compat.futures]\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\nltk\\twitter\\__init__.py:22: UserWarning: The twython library has not been installed. Some functionality from the twitter package will not be available.\n",
      "  \"The twython library has not been installed. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG:pip._internal.vcs.versioncontrol:Registered VCS backend: bzr\n",
      "DEBUG:pip._internal.vcs.versioncontrol:Registered VCS backend: git\n",
      "DEBUG:pip._internal.vcs.versioncontrol:Registered VCS backend: hg\n",
      "DEBUG:pip._internal.vcs.versioncontrol:Registered VCS backend: svn\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\skimage\\novice\\__init__.py:103: UserWarning: The `skimage.novice` module was deprecated in version 0.14. It will be removed in 0.16.\n",
      "  warnings.warn(\"The `skimage.novice` module was deprecated in version 0.14. \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\skimage\\viewer\\utils\\core.py:10: UserWarning: Recommended matplotlib backend is `Agg` for full skimage.viewer functionality.\n",
      "  warn(\"Recommended matplotlib backend is `Agg` for full \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\qtawesome\\iconic_font.py:301: UserWarning: You need to have a running QApplication to use QtAwesome!\n",
      "  warnings.warn(\"You need to have a running \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\pkgutil.py:107: VisibleDeprecationWarning: zmq.eventloop.minitornado is deprecated in pyzmq 14.0 and will be removed.\n",
      "    Install tornado itself to use zmq with the tornado IOLoop.\n",
      "    \n",
      "  yield from walk_packages(path, info.name+'.', onerror)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crypto              brain_six           markupsafe          socketserver\n",
      "Cython              brain_ssl           marshal             socks\n",
      "IPython             brain_subprocess    math                sockshandler\n",
      "OpenSSL             brain_threading     matplotlib          sortedcollections\n",
      "PIL                 brain_typing        mccabe              sortedcontainers\n",
      "PyQt5               brain_uuid          menuinst            soupsieve\n",
      "__future__          bs4                 mimetypes           sphinx\n",
      "_abc                builtins            mistune             sphinxcontrib\n",
      "_ast                bz2                 mkl                 spyder\n",
      "_asyncio            cProfile            mkl_fft             spyder_breakpoints\n",
      "_bisect             calendar            mkl_random          spyder_io_dcm\n",
      "_blake2             certifi             mmap                spyder_io_hdf5\n",
      "_bootlocale         cffi                mmapfile            spyder_kernels\n",
      "_bz2                cgi                 mmsystem            spyder_profiler\n",
      "_cffi_backend       cgitb               mock                spyder_pylint\n",
      "_codecs             chardet             modulefinder        sqlalchemy\n",
      "_codecs_cn          chunk               more_itertools      sqlite3\n",
      "_codecs_hk          click               mpmath              sre_compile\n",
      "_codecs_iso2022     cloudpickle         msgpack             sre_constants\n",
      "_codecs_jp          clyent              msilib              sre_parse\n",
      "_codecs_kr          cmath               msvcrt              ssl\n",
      "_codecs_tw          cmd                 multipledispatch    sspi\n",
      "_collections        code                multiprocessing     sspicon\n",
      "_collections_abc    codecs              navigator_updater   stat\n",
      "_compat_pickle      codeop              nbconvert           statistics\n",
      "_compression        collections         nbformat            statsmodels\n",
      "_contextvars        colorama            netbios             storemagic\n",
      "_csv                colorsys            netrc               string\n",
      "_ctypes             commctrl            networkx            stringprep\n",
      "_ctypes_test        compileall          nltk                struct\n",
      "_datetime           comtypes            nntplib             subprocess\n",
      "_decimal            concurrent          nose                sunau\n",
      "_dummy_thread       conda               notebook            symbol\n",
      "_elementtree        conda_build         nt                  sympy\n",
      "_functools          conda_env           ntpath              sympyprinting\n",
      "_hashlib            conda_package_handling ntsecuritycon       symtable\n",
      "_heapq              conda_verify        nturl2path          sys\n",
      "_imp                configparser        numba               sysconfig\n",
      "_io                 contextlib          numbers             tables\n",
      "_json               contextlib2         numexpr             tabnanny\n",
      "_locale             contextvars         numpy               tarfile\n",
      "_lsprof             copy                numpydoc            tblib\n",
      "_lzma               copyreg             odbc                telnetlib\n",
      "_markupbase         crypt               olefile             tempfile\n",
      "_md5                cryptography        opcode              terminado\n",
      "_msi                csv                 openpyxl            test\n",
      "_multibytecodec     ctypes              operator            test_data\n",
      "_multiprocessing    curl                optparse            test_pycosat\n",
      "_nsis               curses              os                  testpath\n",
      "_opcode             cwp                 packaging           tests\n",
      "_operator           cycler              pandas              textwrap\n",
      "_osx_support        cython              pandocfilters       this\n",
      "_overlapped         cythonmagic         parser              threading\n",
      "_pickle             cytoolz             parso               time\n",
      "_py_abc             dask                partd               timeit\n",
      "_pydecimal          dataclasses         past                timer\n",
      "_pyio               datetime            path                tkinter\n",
      "_pylief             dateutil            pathlib             tlz\n",
      "_pyrsistent_version dbi                 pathlib2            token\n",
      "_pytest             dbm                 patsy               tokenize\n",
      "_queue              dde                 pdb                 toolz\n",
      "_random             decimal             pep8                tornado\n",
      "_sha1               decorator           perfmon             tqdm\n",
      "_sha256             defusedxml          pickle              trace\n",
      "_sha3               difflib             pickleshare         traceback\n",
      "_sha512             dis                 pickletools         tracemalloc\n",
      "_signal             distributed         pip                 traitlets\n",
      "_sitebuiltins       distutils           pipes               tty\n",
      "_socket             doctest             pkg_resources       turtle\n",
      "_sqlite3            docutils            pkginfo             turtledemo\n",
      "_sre                dummy_threading     pkgutil             types\n",
      "_ssl                easy_install        platform            typing\n",
      "_stat               email               plistlib            unicodecsv\n",
      "_string             encodings           pluggy              unicodedata\n",
      "_strptime           ensurepip           ply                 unittest\n",
      "_struct             entrypoints         poplib              urllib\n",
      "_symtable           enum                posixpath           urllib3\n",
      "_system_path        errno               pprint              uu\n",
      "_testbuffer         et_xmlfile          profile             uuid\n",
      "_testcapi           fastcache           prometheus_client   venv\n",
      "_testconsole        faulthandler        prompt_toolkit      warnings\n",
      "_testimportmultiple filecmp             pstats              wave\n",
      "_testmultiphase     fileinput           psutil              wcwidth\n",
      "_thread             filelock            pty                 weakref\n",
      "_threading_local    flask               pvectorc            webbrowser\n",
      "_tkinter            fnmatch             py                  webencodings\n",
      "_tracemalloc        formatter           py_compile          werkzeug\n",
      "_warnings           fractions           pyclbr              wheel\n",
      "_weakref            fsspec              pycodestyle         widgetsnbextension\n",
      "_weakrefset         ftplib              pycosat             win2kras\n",
      "_win32sysloader     functools           pycparser           win32api\n",
      "_winapi             future              pycurl              win32clipboard\n",
      "_winxptheme         gc                  pydoc               win32com\n",
      "_yaml               genericpath         pydoc_data          win32con\n",
      "abc                 getopt              pyexpat             win32console\n",
      "adodbapi            getpass             pyflakes            win32cred\n",
      "afxres              gettext             pygments            win32crypt\n",
      "aifc                gevent              pylab               win32cryptcon\n",
      "alabaster           glob                pylint              win32event\n",
      "anaconda_navigator  glob2               pyodbc              win32evtlog\n",
      "anaconda_project    greenlet            pyparsing           win32evtlogutil\n",
      "antigravity         gzip                pyreadline          win32file\n",
      "argparse            h5py                pyrsistent          win32gui\n",
      "array               hashlib             pytest              win32gui_struct\n",
      "asn1crypto          heapdict            pytest_arraydiff    win32help\n",
      "ast                 heapq               pytest_doctestplus  win32inet\n",
      "astroid             hmac                pytest_openfiles    win32inetcon\n",
      "astropy             html                pytest_remotedata   win32job\n",
      "asynchat            html5lib            pythoncom           win32lz\n",
      "asyncio             http                pytz                win32net\n",
      "asyncore            idlelib             pywin               win32netcon\n",
      "atexit              idna                pywin32_testutil    win32pdh\n",
      "atomicwrites        imageio             pywintypes          win32pdhquery\n",
      "attr                imagesize           pywt                win32pdhutil\n",
      "audioop             imaplib             pyximport           win32pipe\n",
      "autoreload          imghdr              qtawesome           win32print\n",
      "babel               imp                 qtconsole           win32process\n",
      "backcall            importlib           qtpy                win32profile\n",
      "backports           importlib_metadata  queue               win32ras\n",
      "base64              inspect             quopri              win32rcparser\n",
      "bdb                 io                  random              win32security\n",
      "binascii            ipaddress           rasutil             win32service\n",
      "binhex              ipykernel           re                  win32serviceutil\n",
      "binstar_client      ipykernel_launcher  readline            win32timezone\n",
      "bisect              ipython_genutils    regcheck            win32trace\n",
      "bitarray            ipywidgets          regutil             win32traceutil\n",
      "bkcharts            isapi               reprlib             win32transaction\n",
      "bleach              isort               requests            win32ts\n",
      "bokeh               isympy              rlcompleter         win32ui\n",
      "boto                itertools           rmagic              win32uiole\n",
      "bottleneck          itsdangerous        rope                win32verstamp\n",
      "brain_argparse      jdcal               ruamel_yaml         win32wnet\n",
      "brain_attrs         jedi                run                 win_inet_pton\n",
      "brain_builtin_inference jinja2              runpy               win_unicode_console\n",
      "brain_collections   joblib              sched               wincertstore\n",
      "brain_crypt         json                scipy               winerror\n",
      "brain_curses        json5               scripts             winioctlcon\n",
      "brain_dataclasses   jsonschema          seaborn             winnt\n",
      "brain_dateutil      jupyter             secrets             winperf\n",
      "brain_fstrings      jupyter_client      select              winpty\n",
      "brain_functools     jupyter_console     selectors           winreg\n",
      "brain_gi            jupyter_core        send2trash          winsound\n",
      "brain_hashlib       jupyterlab          servicemanager      winxpgui\n",
      "brain_http          jupyterlab_server   setuptools          winxptheme\n",
      "brain_io            keyring             shelve              wrapt\n",
      "brain_mechanize     keyword             shlex               wsgiref\n",
      "brain_multiprocessing kiwisolver          shutil              xdrlib\n",
      "brain_namedtuple_enum lazy_object_proxy   signal              xlrd\n",
      "brain_nose          lib2to3             simplegeneric       xlsxwriter\n",
      "brain_numpy_core_fromnumeric libarchive          singledispatch      xlwings\n",
      "brain_numpy_core_function_base libfuturize         singledispatch_helpers xlwt\n",
      "brain_numpy_core_multiarray libpasteurize       sip                 xml\n",
      "brain_numpy_core_numeric lief                sipconfig           xmlrpc\n",
      "brain_numpy_core_numerictypes linecache           sipdistutils        xxsubtype\n",
      "brain_numpy_core_umath llvmlite            site                yaml\n",
      "brain_numpy_ndarray locale              six                 zict\n",
      "brain_numpy_random_mtrand locket              skimage             zipapp\n",
      "brain_numpy_utils   logging             sklearn             zipfile\n",
      "brain_pkg_resources lxml                smtpd               zipimport\n",
      "brain_pytest        lzma                smtplib             zipp\n",
      "brain_qt            macpath             sndhdr              zlib\n",
      "brain_random        mailbox             snowballstemmer     zmq\n",
      "brain_re            mailcap             socket              \n",
      "\n",
      "Enter any module name to get more help.  Or, type \"modules spam\" to search\n",
      "for modules whose name or summary contain the string \"spam\".\n",
      "\n",
      "DEBUG:matplotlib.pyplot:Loaded backend module://ipykernel.pylab.backend_inline version unknown.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.version)\n",
    "help(\"modules\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-33-6bdc1f965e7c>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-33-6bdc1f965e7c>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    conda install -c conda-forge tensorflow\u001b[0m\n\u001b[1;37m                ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "conda install -c conda-forge tensorflow\n",
    "# conda install -c conda-forge/label/broken tensorflow\n",
    "# conda install -c conda-forge/label/cf201901 tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "asn1crypto==1.3.0\n",
      "attrs==19.3.0\n",
      "Automat==0.8.0\n",
      "backcall==0.1.0\n",
      "bleach==3.1.0\n",
      "certifi==2019.11.28\n",
      "cffi==1.13.2\n",
      "chardet==3.0.4\n",
      "cloudpickle==1.2.2\n",
      "colorama==0.4.3\n",
      "conda==4.8.1\n",
      "conda-package-handling==1.6.0\n",
      "constantly==15.1.0\n",
      "cryptography==2.8\n",
      "cssselect==1.1.0\n",
      "cycler==0.10.0\n",
      "cytoolz==0.10.1\n",
      "dask==2.10.0\n",
      "decorator==4.4.1\n",
      "defusedxml==0.6.0\n",
      "entrypoints==0.3\n",
      "fast-histogram==0.7\n",
      "graphviz==0.13.2\n",
      "h5py==2.10.0\n",
      "hyperlink==19.0.0\n",
      "idna==2.8\n",
      "imageio==2.6.1\n",
      "importlib-metadata==1.4.0\n",
      "incremental==17.5.0\n",
      "ipykernel==5.1.4\n",
      "ipython==7.11.1\n",
      "ipython-genutils==0.2.0\n",
      "jedi==0.16.0\n",
      "Jinja2==2.10.3\n",
      "joblib==0.14.0\n",
      "json5==0.8.5\n",
      "jsonschema==3.2.0\n",
      "jupyter-client==5.3.4\n",
      "jupyter-core==4.6.1\n",
      "jupyterlab==1.0.2\n",
      "jupyterlab-server==1.0.6\n",
      "Keras==2.3.1\n",
      "Keras-Applications==1.0.8\n",
      "Keras-Preprocessing==1.1.0\n",
      "kiwisolver==1.1.0\n",
      "lime==0.1.1.37\n",
      "llvmlite==0.30.0\n",
      "lxml==4.5.0\n",
      "MarkupSafe==1.1.1\n",
      "matplotlib==3.1.0\n",
      "menuinst==1.4.16\n",
      "mistune==0.8.4\n",
      "mkl-fft==1.0.15\n",
      "mkl-random==1.1.0\n",
      "mkl-service==2.3.0\n",
      "more-itertools==8.0.2\n",
      "nbconvert==5.6.1\n",
      "nbformat==5.0.4\n",
      "networkx==2.4\n",
      "nltk==3.4.5\n",
      "notebook==6.0.3\n",
      "numba==0.46.0\n",
      "numpy==1.18.1\n",
      "olefile==0.46\n",
      "pandas==0.24.2\n",
      "pandocfilters==1.4.2\n",
      "parsel==1.5.2\n",
      "parso==0.6.0\n",
      "patsy==0.5.1\n",
      "pickleshare==0.7.5\n",
      "Pillow==7.0.0\n",
      "prometheus-client==0.7.1\n",
      "prompt-toolkit==3.0.2\n",
      "Protego==0.1.16\n",
      "psycopg2==2.8.3\n",
      "pyasn1==0.4.8\n",
      "pyasn1-modules==0.2.8\n",
      "pycosat==0.6.3\n",
      "pycparser==2.19\n",
      "PyDispatcher==2.0.5\n",
      "pydotplus==2.0.2\n",
      "Pygments==2.5.2\n",
      "PyHamcrest==2.0.0\n",
      "pyOpenSSL==19.1.0\n",
      "pyparsing==2.4.6\n",
      "pyrsistent==0.15.7\n",
      "PySocks==1.7.1\n",
      "python-dateutil==2.8.1\n",
      "pytz==2019.3\n",
      "PyWavelets==1.1.1\n",
      "pywin32==227\n",
      "pywinpty==0.5.7\n",
      "PyYAML==5.3\n",
      "pyzmq==18.1.0\n",
      "queuelib==1.5.0\n",
      "requests==2.22.0\n",
      "rise==5.6.0\n",
      "ruamel-yaml==0.15.87\n",
      "scikit-image==0.15.0\n",
      "scikit-learn==0.22\n",
      "scipy==1.3.0\n",
      "Scrapy==1.8.0\n",
      "seaborn==0.9.0\n",
      "Send2Trash==1.5.0\n",
      "service-identity==18.1.0\n",
      "six==1.14.0\n",
      "sklearn==0.0\n",
      "SQLAlchemy==1.3.8\n",
      "statsmodels==0.10.1\n",
      "terminado==0.8.3\n",
      "testpath==0.4.4\n",
      "toolz==0.10.0\n",
      "tornado==6.0.3\n",
      "tqdm==4.42.0\n",
      "traitlets==4.3.3\n",
      "Twisted==19.10.0\n",
      "umap-learn==0.3.10\n",
      "urllib3==1.25.8\n",
      "w3lib==1.21.0\n",
      "wcwidth==0.1.7\n",
      "webencodings==0.5.1\n",
      "win-inet-pton==1.1.0\n",
      "wincertstore==0.2\n",
      "zipp==0.6.0\n",
      "zope.interface==4.7.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip freeze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pip3' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-38-8fa0e15ea08f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpip3\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mversion\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'pip3' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pip\n",
      "  Downloading pip-20.0.2-py2.py3-none-any.whl (1.4 MB)\n",
      "Installing collected packages: pip\n",
      "  Attempting uninstall: pip\n",
      "    Found existing installation: pip 20.0.2\n",
      "    Uninstalling pip-20.0.2:\n",
      "      Successfully uninstalled pip-20.0.2\n",
      "Successfully installed pip-20.0.2\n"
     ]
    }
   ],
   "source": [
    "!python -m pip install --upgrade --force-reinstall pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement tensorflow (from versions: none)\n",
      "ERROR: No matching distribution found for tensorflow\n"
     ]
    }
   ],
   "source": [
    "!pip install --user --upgrade tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement tensorflow==1.14.0 (from versions: none)\n",
      "ERROR: No matching distribution found for tensorflow==1.14.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --ignore-installed --upgrade tensorflow==1.14.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading https://files.pythonhosted.org/packages/34/d5/ce8c17971067c0184c9045112b755be5461d5ce5253ef65a367e1298d7c5/tensorflow-2.1.0-cp37-cp37m-win_amd64.whl (355.8MB)\n",
      "Collecting google-pasta>=0.1.6 (from tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/c3/fd/1e86bc4837cc9a3a5faf3db9b1854aa04ad35b5f381f9648fbe81a6f94e4/google_pasta-0.1.8-py3-none-any.whl (57kB)\n",
      "Collecting protobuf>=3.8.0 (from tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/92/30/1b7ccde09bf0c535d11f18a574ed7d7572c729a8f754fd568b297be08b61/protobuf-3.11.3-cp37-cp37m-win_amd64.whl (1.0MB)\n",
      "Collecting astor>=0.6.0 (from tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/c3/88/97eef84f48fa04fbd6750e62dcceafba6c63c81b7ac1420856c8dcc0a3f9/astor-0.8.1-py2.py3-none-any.whl\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (1.12.0)\n",
      "Collecting absl-py>=0.7.0 (from tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/1a/53/9243c600e047bd4c3df9e69cfabc1e8004a82cac2e0c484580a78a94ba2a/absl-py-0.9.0.tar.gz (104kB)\n",
      "Collecting grpcio>=1.8.6 (from tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/a7/6d/99aba8db04bf58193ed157dfe7e848494b93dd8aa3f6a4d1edfef318779c/grpcio-1.27.2-cp37-cp37m-win_amd64.whl (1.9MB)\n",
      "Collecting scipy==1.4.1; python_version >= \"3\" (from tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/61/51/046cbc61c7607e5ecead6ff1a9453fba5e7e47a5ea8d608cc7036586a5ef/scipy-1.4.1-cp37-cp37m-win_amd64.whl (30.9MB)\n",
      "Collecting tensorflow-estimator<2.2.0,>=2.1.0rc0 (from tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/18/90/b77c328a1304437ab1310b463e533fa7689f4bfc41549593056d812fab8e/tensorflow_estimator-2.1.0-py2.py3-none-any.whl (448kB)\n",
      "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (0.33.6)\n",
      "Collecting opt-einsum>=2.3.2 (from tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/b2/49/2233e63052d5686c72131b579837ddfb98ba9dd0b92bb91efcb441ada8ce/opt_einsum-3.2.0-py3-none-any.whl (63kB)\n",
      "Collecting tensorboard<2.2.0,>=2.1.0 (from tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/d9/41/bbf49b61370e4f4d245d4c6051dfb6db80cec672605c91b1652ac8cc3d38/tensorboard-2.1.1-py3-none-any.whl (3.8MB)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (1.11.2)\n",
      "Collecting keras-preprocessing>=1.1.0 (from tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/28/6a/8c1f62c37212d9fc441a7e26736df51ce6f0e38455816445471f10da4f0a/Keras_Preprocessing-1.1.0-py2.py3-none-any.whl\n",
      "Collecting keras-applications>=1.0.8 (from tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl\n",
      "Collecting gast==0.2.2 (from tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/4e/35/11749bf99b2d4e3cceb4d55ca22590b0d7c2c62b9de38ac4a4a7f4687421/gast-0.2.2.tar.gz\n",
      "Collecting termcolor>=1.1.0 (from tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/8a/48/a76be51647d0eb9f10e2a4511bf3ffb8cc1e6b14e9e4fab46173aa79f981/termcolor-1.1.0.tar.gz\n",
      "Requirement already satisfied: numpy<2.0,>=1.16.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (1.16.5)\n",
      "Requirement already satisfied: setuptools in c:\\programdata\\anaconda3\\lib\\site-packages (from protobuf>=3.8.0->tensorflow) (41.4.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow) (2.22.0)\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1 (from tensorboard<2.2.0,>=2.1.0->tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/7b/b8/88def36e74bee9fce511c9519571f4e485e890093ab7442284f4ffaef60b/google_auth_oauthlib-0.4.1-py2.py3-none-any.whl\n",
      "Collecting google-auth<2,>=1.6.3 (from tensorboard<2.2.0,>=2.1.0->tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/5a/8d/e2ebbd0502627ed0d8a408162020e1c0792f088b49fddeedaaeebc206ed7/google_auth-1.11.2-py2.py3-none-any.whl (76kB)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow) (0.16.0)\n",
      "Collecting markdown>=2.6.8 (from tensorboard<2.2.0,>=2.1.0->tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/ab/c4/ba46d44855e6eb1770a12edace5a165a0c6de13349f592b9036257f3c3d3/Markdown-3.2.1-py2.py3-none-any.whl (88kB)\n",
      "Requirement already satisfied: h5py in c:\\programdata\\anaconda3\\lib\\site-packages (from keras-applications>=1.0.8->tensorflow) (2.9.0)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow) (1.24.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow) (2019.9.11)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow) (2.8)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow) (3.0.4)\n",
      "Collecting requests-oauthlib>=0.7.0 (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/a3/12/b92740d845ab62ea4edf04d2f4164d82532b5a0b03836d4d4e71c6f3d379/requests_oauthlib-1.3.0-py2.py3-none-any.whl\n",
      "Collecting cachetools<5.0,>=2.0.0 (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/08/6a/abf83cb951617793fd49c98cb9456860f5df66ff89883c8660aa0672d425/cachetools-4.0.0-py3-none-any.whl\n",
      "Collecting pyasn1-modules>=0.2.1 (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/95/de/214830a981892a3e286c3794f41ae67a4495df1108c3da8a9f62159b9a9d/pyasn1_modules-0.2.8-py2.py3-none-any.whl\n",
      "Collecting rsa<4.1,>=3.1.4 (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/02/e5/38518af393f7c214357079ce67a317307936896e961e35450b70fad2a9cf/rsa-4.0-py2.py3-none-any.whl\n",
      "Collecting oauthlib>=3.0.0 (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/05/57/ce2e7a8fa7c0afb54a0581b14a65b56e62b5759dbc98e80627142b8a3704/oauthlib-3.1.0-py2.py3-none-any.whl (147kB)\n",
      "Collecting pyasn1<0.5.0,>=0.4.6 (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/62/1e/a94a8d635fa3ce4cfc7f506003548d0a2447ae76fd5ca53932970fe3053f/pyasn1-0.4.8-py2.py3-none-any.whl\n",
      "Building wheels for collected packages: absl-py, gast, termcolor\n",
      "  Building wheel for absl-py (setup.py): started\n",
      "  Building wheel for absl-py (setup.py): finished with status 'done'\n",
      "  Created wheel for absl-py: filename=absl_py-0.9.0-cp37-none-any.whl size=121936 sha256=f919a12851c2972c875d25ba46c140b0f2b3efb9071137b31b013b0c2abdfef6\n",
      "  Stored in directory: C:\\Users\\M246047\\AppData\\Local\\pip\\Cache\\wheels\\8e\\28\\49\\fad4e7f0b9a1227708cbbee4487ac8558a7334849cb81c813d\n",
      "  Building wheel for gast (setup.py): started\n",
      "  Building wheel for gast (setup.py): finished with status 'done'\n",
      "  Created wheel for gast: filename=gast-0.2.2-cp37-none-any.whl size=7546 sha256=742fc0584abebb6d463985c1ace67a76515d73bcaa9a26e6d87f5ec025fa5668\n",
      "  Stored in directory: C:\\Users\\M246047\\AppData\\Local\\pip\\Cache\\wheels\\5c\\2e\\7e\\a1d4d4fcebe6c381f378ce7743a3ced3699feb89bcfbdadadd\n",
      "  Building wheel for termcolor (setup.py): started\n",
      "  Building wheel for termcolor (setup.py): finished with status 'done'\n",
      "  Created wheel for termcolor: filename=termcolor-1.1.0-cp37-none-any.whl size=4835 sha256=5cd2c1698fd62a335e716485f03b6160d8ba765aa6641b78e6a8bde185242c5e\n",
      "  Stored in directory: C:\\Users\\M246047\\AppData\\Local\\pip\\Cache\\wheels\\7c\\06\\54\\bc84598ba1daf8f970247f550b175aaaee85f68b4b0c5ab2c6\n",
      "Successfully built absl-py gast termcolor\n",
      "Installing collected packages: google-pasta, protobuf, astor, absl-py, grpcio, scipy, tensorflow-estimator, opt-einsum, cachetools, pyasn1, pyasn1-modules, rsa, google-auth, oauthlib, requests-oauthlib, google-auth-oauthlib, markdown, tensorboard, keras-preprocessing, keras-applications, gast, termcolor, tensorflow\n",
      "  Found existing installation: scipy 1.3.1\n",
      "    Uninstalling scipy-1.3.1:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not install packages due to an EnvironmentError: [WinError 5] Access is denied: 'c:\\\\programdata\\\\anaconda3\\\\lib\\\\site-packages\\\\scipy\\\\cluster\\\\hierarchy.py'\n",
      "Consider using the `--user` option or check the permissions.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting umap\n",
      "Installing collected packages: umap\n",
      "Successfully installed umap-0.1.1\n"
     ]
    }
   ],
   "source": [
    "!pip install umap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import umap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-22743e1cca37>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# TensorFlow's import convention is tf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "# TensorFlow's import convention is tf\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Components of TensorFlow\n",
    "Now, before we start going off and building our own models, we need to know more about how TensorFlow thinks. Tensor flows conceives of the world and modeling within it with a very specific set of components. Understanding these components will facilitate our understanding of TensorFlow and how to best use it to build our models.\n",
    "\n",
    "In this section, we'll go through those core elements, setting the stage for us to build models later on.\n",
    "\n",
    "### Tensors\n",
    "The core data structure in TensorFlow is called a tensor. A tensor will have a lot of similarity to a numpy array. Much like an array, a tensor is specified with [ and ]. Similarly, it can come in n-dimensions, reaching whatever level of complexity the problem necessitates.\n",
    "\n",
    "Let's build a few tensors below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[3, 2, 1]\n",
    "[[3, 2], [1, 3]]\n",
    "[[[1], [2]], [[1], [2]]]\n",
    "2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we talk about tensors, one of their defining characteristics is its rank. The rank is just the dimension of the tensor.\n",
    "\n",
    "Can you figure out the rank of the tensors above?\n",
    "\n",
    "Well, that first tensor is simply rank 1, a single dimensional tensor. The next one adds another dimension, as does the one after that. However, what about that final tensor? Is it a tensor at all?\n",
    "\n",
    "It is! A scalar value like this can be considered a tensor of rank 0, as it is just a single value.\n",
    "\n",
    "Tensors are how we'll handle data in Tensor flow. When we get inputs, we'll leave them as tensors and run those tensors through the various nodes and steps of our model. We will also likely return a tensor as our output.\n",
    "\n",
    "So far, tensors sound a lot like numpy arrays, and they are. There are many ways we can conceive of tensors, but the key is that they easily support higher dimensions than the typical dataframe, with less syntactical nomenclature like column names or indices, and are more robust for our modeling uses than a simple numpy array.\n",
    "\n",
    "Tensors are easily converted to NumPy arrays using .eval(). Before running this method, tensors are more like placeholder structures of a shape and size, with strong data typing and holding the data given to them (if you have given them data), but the structure and its contents remain distinct.\n",
    "\n",
    "Nodes\n",
    "The other key object in TensorFlow, at its most rudimentary, is the node. Nodes are places where things can happen in our model. Let's start with an example.\n",
    "\n",
    "The first kind of node we'll discuss is the constant. Let's implement one!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-242652d0813e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Create the Node\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mnode_const\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m70\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# Print the Node\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_const\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tf' is not defined"
     ]
    }
   ],
   "source": [
    "# Create the Node\n",
    "node_const = tf.constant(70)\n",
    "\n",
    "# Print the Node\n",
    "print(node_const)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a few things to note here.\n",
    "\n",
    "Firstly, it was pretty simple to create the node, we defined it like we would any other variable. However, note that when we print the node, it printed a description of the node rather than its value. This is because nodes are much more than just constants. Even though the node we created in this case was a constant, the class itself supports a wider range of functionalities with the printed output reflecting that potential diversity.\n",
    "\n",
    "To better explain what we mean, let's make another node. This one will be for addition."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checkpoint 5 - Let's talk Keras\n",
    "So we said in the beginning that we'd use Keras to build Neural Networks, but so far we've been all about the TensorFlow. That changes now. But before we can start using Keras, we need to discuss how it's different from TensorFlow.\n",
    "\n",
    "Keras is a much more user friendly system than TensorFlow. It was designed to work quickly while maintaining as much adaptability as possible. Of course sacrifices are still made, and it is nowhere near as flexible as TensorFlow.\n",
    "\n",
    "Hopefully through the past two lessons you have seen the very granular controls that TensorFlow gives you for setting up a session and creating a model. Keras is not that kind of program. Made specifically for neural networks, Keras aims to give maximum flexibility while maintaining a relatively easy frame of use. As such it emphasizes modularity of customizability. How does it do that? While, it all comes down to how Keras thinks about structures. Instead of Nodes and Variables and the like, Keras thinks in terms of Models and Layers.\n",
    "\n",
    "Keras has Layers...\n",
    "The simplest level of structure in Keras is the layer. These are like the layers we discussed in the previous neural networks section, a set of nodes or perceptrons that connect in some form to both the preceding and following layers.\n",
    "\n",
    "There are many different kinds of layers in Keras. Perhaps the most common of these layer types is Dense. Dense layers are also called fully connected layers, where each node connects to each node in the following layer.\n",
    "\n",
    "There is a (lot more to layers) (https://keras.io/layers/about-keras-layers/) than just Dense. You have convolutional layers or recurrent layers or many other kinds that we haven't even discussed. The documentation here is really strong, and as you expand the kinds of networks you build, we recommend referring back to it. To explain every possible type of layer here would be work worth of a dissertation, if not several. Weâ€™d generally advise you to stick to structures you read about elsewhere rather than attempting to innovate in this space until youâ€™ve spent a lot more time working on these kinds of models.\n",
    "\n",
    "Model Types\n",
    "Models in Keras come in two varieties: Sequential and Complex.\n",
    "\n",
    "Sequential is the simpler of the two to implement, and implies a basic stack of layers with a linear progression. The more complex models (made through the Keras API) have any kind of graphical structure you could imagine.\n",
    "\n",
    "So how do you make a model? You add layers.\n",
    "\n",
    "from keras.models import Sequential\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "from keras.layers import Dense, Activation\n",
    "\n",
    "model.add(Dense(units=100, input_dim=100))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(units=10))\n",
    "model.add(Activation('softmax'))\n",
    "This sets up a sequential model, and then adds two layers with two different activation functions. These layers are fully connected, or â€˜denseâ€™. Also note that the first layer specifies units (which is the width of the layer) and the input dimension (which is necessary for the first layer in order to specify the number of input variables).\n",
    "\n",
    "Also, your last layer has a number of units that is the number of outputs you want. So ten outputs would be for a ten class classifier, with a softmax function to pick which category (again, there are more functions to choose from, this is just one of the most common for classification problems).\n",
    "\n",
    "Compile and Fit\n",
    "Once you've established the model, you have to compile it and then fit it.\n",
    "\n",
    "To compile the model specify two things: loss and optimizer. The loss function explains what we'd want to minimize, as before, and Keras has several kinds of loss functions built in under keras.losses. You can find the one that would be most appropriate to your given problem.\n",
    "\n",
    "The optimizer is something we addressed in the previous lesson with the implementation of gradient descent, the primary optimizer we've covered thus far, though under keras.optimizers there are several other options.\n",
    "\n",
    "These are the key components for working with Keras: now is the time to build something with them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checkpoint 7 - Challenge\n",
    "Now take your Keras skills and go build another neural network. Pick your data set, but it should be one of abstract types, possibly even nonnumeric, and use Keras to make five implementations of your network. Compare them both in computational complexity as well as in accuracy and given that tradeoff decide which one you like best.\n",
    "\n",
    "Your dataset should be sufficiently large for a neural network to perform well (samples should really be in the thousands here) and try to pick something that takes advantage of neural networksâ€™ ability to have both feature extraction and supervised capabilities, so donâ€™t pick something with an easy to consume list of features already generated for you (though neural networks can still be useful in those contexts).\n",
    "\n",
    "Note that if you want to use an unprocessed image dataset, scikit-image is a useful package for converting to importable numerics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keras\n",
      "  Using cached https://files.pythonhosted.org/packages/ad/fd/6bfe87920d7f4fd475acd28500a42482b6b84479832bdc0fe9e589a60ceb/Keras-2.3.1-py2.py3-none-any.whl\n",
      "Collecting keras-applications>=1.0.6 (from keras)\n",
      "  Using cached https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl\n",
      "Requirement already satisfied: six>=1.9.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from keras) (1.12.0)\n",
      "Requirement already satisfied: h5py in c:\\programdata\\anaconda3\\lib\\site-packages (from keras) (2.9.0)\n",
      "Requirement already satisfied: pyyaml in c:\\programdata\\anaconda3\\lib\\site-packages (from keras) (5.1.2)\n",
      "Collecting keras-preprocessing>=1.0.5 (from keras)\n",
      "  Using cached https://files.pythonhosted.org/packages/28/6a/8c1f62c37212d9fc441a7e26736df51ce6f0e38455816445471f10da4f0a/Keras_Preprocessing-1.1.0-py2.py3-none-any.whl\n",
      "Requirement already satisfied: numpy>=1.9.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from keras) (1.16.5)\n",
      "Requirement already satisfied: scipy>=0.14 in c:\\programdata\\anaconda3\\lib\\site-packages (from keras) (1.3.1)\n",
      "Installing collected packages: keras-applications, keras-preprocessing, keras\n",
      "Successfully installed keras-2.3.1 keras-applications-1.0.8 keras-preprocessing-1.1.0\n"
     ]
    }
   ],
   "source": [
    "!pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Using cached https://files.pythonhosted.org/packages/34/d5/ce8c17971067c0184c9045112b755be5461d5ce5253ef65a367e1298d7c5/tensorflow-2.1.0-cp37-cp37m-win_amd64.whl\n",
      "Requirement already satisfied: google-pasta>=0.1.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (0.1.8)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (1.11.2)\n",
      "Requirement already satisfied: numpy<2.0,>=1.16.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (1.16.5)\n",
      "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (0.33.6)\n",
      "Collecting tensorboard<2.2.0,>=2.1.0 (from tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/d9/41/bbf49b61370e4f4d245d4c6051dfb6db80cec672605c91b1652ac8cc3d38/tensorboard-2.1.1-py3-none-any.whl\n",
      "Collecting gast==0.2.2 (from tensorflow)\n",
      "Collecting scipy==1.4.1; python_version >= \"3\" (from tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/61/51/046cbc61c7607e5ecead6ff1a9453fba5e7e47a5ea8d608cc7036586a5ef/scipy-1.4.1-cp37-cp37m-win_amd64.whl\n",
      "Requirement already satisfied: absl-py>=0.7.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (0.9.0)\n",
      "Collecting opt-einsum>=2.3.2 (from tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/b2/49/2233e63052d5686c72131b579837ddfb98ba9dd0b92bb91efcb441ada8ce/opt_einsum-3.2.0-py3-none-any.whl\n",
      "Collecting tensorflow-estimator<2.2.0,>=2.1.0rc0 (from tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/18/90/b77c328a1304437ab1310b463e533fa7689f4bfc41549593056d812fab8e/tensorflow_estimator-2.1.0-py2.py3-none-any.whl\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (1.12.0)\n",
      "Requirement already satisfied: protobuf>=3.8.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (3.11.3)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (1.27.2)\n",
      "Requirement already satisfied: astor>=0.6.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (0.8.1)\n",
      "Requirement already satisfied: keras-applications>=1.0.8 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (1.0.8)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (1.1.0)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow)\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1 (from tensorboard<2.2.0,>=2.1.0->tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/7b/b8/88def36e74bee9fce511c9519571f4e485e890093ab7442284f4ffaef60b/google_auth_oauthlib-0.4.1-py2.py3-none-any.whl\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow) (2.22.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow) (0.16.0)\n",
      "Collecting google-auth<2,>=1.6.3 (from tensorboard<2.2.0,>=2.1.0->tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/5a/8d/e2ebbd0502627ed0d8a408162020e1c0792f088b49fddeedaaeebc206ed7/google_auth-1.11.2-py2.py3-none-any.whl\n",
      "Collecting markdown>=2.6.8 (from tensorboard<2.2.0,>=2.1.0->tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/ab/c4/ba46d44855e6eb1770a12edace5a165a0c6de13349f592b9036257f3c3d3/Markdown-3.2.1-py2.py3-none-any.whl\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow) (41.4.0)\n",
      "Requirement already satisfied: h5py in c:\\programdata\\anaconda3\\lib\\site-packages (from keras-applications>=1.0.8->tensorflow) (2.9.0)\n",
      "Collecting requests-oauthlib>=0.7.0 (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/a3/12/b92740d845ab62ea4edf04d2f4164d82532b5a0b03836d4d4e71c6f3d379/requests_oauthlib-1.3.0-py2.py3-none-any.whl\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow) (1.24.2)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow) (2019.9.11)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow) (3.0.4)\n",
      "Collecting cachetools<5.0,>=2.0.0 (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/08/6a/abf83cb951617793fd49c98cb9456860f5df66ff89883c8660aa0672d425/cachetools-4.0.0-py3-none-any.whl\n",
      "Collecting rsa<4.1,>=3.1.4 (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/02/e5/38518af393f7c214357079ce67a317307936896e961e35450b70fad2a9cf/rsa-4.0-py2.py3-none-any.whl\n",
      "Collecting pyasn1-modules>=0.2.1 (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/95/de/214830a981892a3e286c3794f41ae67a4495df1108c3da8a9f62159b9a9d/pyasn1_modules-0.2.8-py2.py3-none-any.whl\n",
      "Collecting oauthlib>=3.0.0 (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/05/57/ce2e7a8fa7c0afb54a0581b14a65b56e62b5759dbc98e80627142b8a3704/oauthlib-3.1.0-py2.py3-none-any.whl\n",
      "Collecting pyasn1>=0.1.3 (from rsa<4.1,>=3.1.4->google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/62/1e/a94a8d635fa3ce4cfc7f506003548d0a2447ae76fd5ca53932970fe3053f/pyasn1-0.4.8-py2.py3-none-any.whl\n",
      "Installing collected packages: oauthlib, requests-oauthlib, cachetools, pyasn1, rsa, pyasn1-modules, google-auth, google-auth-oauthlib, markdown, tensorboard, gast, scipy, opt-einsum, tensorflow-estimator, termcolor, tensorflow\n",
      "  Found existing installation: scipy 1.3.1\n",
      "    Uninstalling scipy-1.3.1:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not install packages due to an EnvironmentError: [WinError 5] Access is denied: 'c:\\\\programdata\\\\anaconda3\\\\lib\\\\site-packages\\\\scipy\\\\cluster\\\\hierarchy.py'\n",
      "Consider using the `--user` option or check the permissions.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip show tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.chdir('C:\\\\Users\\\\M246047\\\\Documents\\\\Python')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "from datetime import datetime, timedelta\n",
    "import re\n",
    "import tensorflow\n",
    "import keras\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['RowNumber', 'CustomerId', 'Surname', 'CreditScore', 'Geography',\n",
      "       'Gender', 'Age', 'Tenure', 'Balance', 'NumOfProducts', 'HasCrCard',\n",
      "       'IsActiveMember', 'EstimatedSalary', 'Exited'],\n",
      "      dtype='object')\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 14 columns):\n",
      "RowNumber          10000 non-null int64\n",
      "CustomerId         10000 non-null int64\n",
      "Surname            10000 non-null object\n",
      "CreditScore        10000 non-null int64\n",
      "Geography          10000 non-null object\n",
      "Gender             10000 non-null object\n",
      "Age                10000 non-null int64\n",
      "Tenure             10000 non-null int64\n",
      "Balance            10000 non-null float64\n",
      "NumOfProducts      10000 non-null int64\n",
      "HasCrCard          10000 non-null int64\n",
      "IsActiveMember     10000 non-null int64\n",
      "EstimatedSalary    10000 non-null float64\n",
      "Exited             10000 non-null int64\n",
      "dtypes: float64(2), int64(9), object(3)\n",
      "memory usage: 1.1+ MB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>15574012</td>\n",
       "      <td>Chu</td>\n",
       "      <td>645</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Male</td>\n",
       "      <td>44</td>\n",
       "      <td>8</td>\n",
       "      <td>113755.78</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>149756.71</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>15592531</td>\n",
       "      <td>Bartlett</td>\n",
       "      <td>822</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>50</td>\n",
       "      <td>7</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10062.80</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>15656148</td>\n",
       "      <td>Obinna</td>\n",
       "      <td>376</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Female</td>\n",
       "      <td>29</td>\n",
       "      <td>4</td>\n",
       "      <td>115046.74</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>119346.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>15792365</td>\n",
       "      <td>He</td>\n",
       "      <td>501</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>44</td>\n",
       "      <td>4</td>\n",
       "      <td>142051.07</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>74940.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>15592389</td>\n",
       "      <td>H?</td>\n",
       "      <td>684</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>27</td>\n",
       "      <td>2</td>\n",
       "      <td>134603.88</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>71725.73</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n",
       "0          1    15634602  Hargrave          619    France  Female   42   \n",
       "1          2    15647311      Hill          608     Spain  Female   41   \n",
       "2          3    15619304      Onio          502    France  Female   42   \n",
       "3          4    15701354      Boni          699    France  Female   39   \n",
       "4          5    15737888  Mitchell          850     Spain  Female   43   \n",
       "5          6    15574012       Chu          645     Spain    Male   44   \n",
       "6          7    15592531  Bartlett          822    France    Male   50   \n",
       "7          8    15656148    Obinna          376   Germany  Female   29   \n",
       "8          9    15792365        He          501    France    Male   44   \n",
       "9         10    15592389        H?          684    France    Male   27   \n",
       "\n",
       "   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0       2       0.00              1          1               1   \n",
       "1       1   83807.86              1          0               1   \n",
       "2       8  159660.80              3          1               0   \n",
       "3       1       0.00              2          0               0   \n",
       "4       2  125510.82              1          1               1   \n",
       "5       8  113755.78              2          1               0   \n",
       "6       7       0.00              2          1               1   \n",
       "7       4  115046.74              4          1               0   \n",
       "8       4  142051.07              2          0               1   \n",
       "9       2  134603.88              1          1               1   \n",
       "\n",
       "   EstimatedSalary  Exited  \n",
       "0        101348.88       1  \n",
       "1        112542.58       0  \n",
       "2        113931.57       1  \n",
       "3         93826.63       0  \n",
       "4         79084.10       0  \n",
       "5        149756.71       1  \n",
       "6         10062.80       0  \n",
       "7        119346.88       1  \n",
       "8         74940.50       0  \n",
       "9         71725.73       0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "churn = pd.read_csv('Bank_Churn.csv')\n",
    "churn = pd.DataFrame(churn)\n",
    "print(churn.columns)\n",
    "print(churn.info())\n",
    "churn.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'll run one hot encoding for categorical variables Geography and Gender and then normalize the data and run it through neural networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 19)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating dummy variables for Geography and Gender\n",
    "churn = pd.concat([churn, pd.get_dummies(churn['Geography'])], axis=1)\n",
    "churn = pd.concat([churn, pd.get_dummies(churn['Gender'])], axis=1)\n",
    "churn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping variables Geography and Gender as we now have dummies\n",
    "churn.drop(columns=['Geography', 'Gender'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
