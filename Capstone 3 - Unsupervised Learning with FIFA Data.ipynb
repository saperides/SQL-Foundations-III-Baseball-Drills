{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sklearn\n",
      "Collecting scikit-learn (from sklearn)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/82/d9/69769d4f79f3b719cc1255f9bd2b6928c72f43e6f74084e3c67db86c4d2b/scikit_learn-0.22.1-cp37-cp37m-macosx_10_6_intel.whl (11.0MB)\n",
      "\u001b[K    100% |████████████████████████████████| 11.0MB 2.2MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.11.0 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from scikit-learn->sklearn) (1.17.0)\n",
      "Collecting joblib>=0.11 (from scikit-learn->sklearn)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/28/5c/cf6a2b65a321c4a209efcdf64c2689efae2cb62661f8f6f4bb28547cf1bf/joblib-0.14.1-py2.py3-none-any.whl (294kB)\n",
      "\u001b[K    100% |████████████████████████████████| 296kB 5.2MB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: scipy>=0.17.0 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from scikit-learn->sklearn) (1.3.1)\n",
      "Installing collected packages: joblib, scikit-learn, sklearn\n",
      "Successfully installed joblib-0.14.1 scikit-learn-0.22.1 sklearn-0.0\n",
      "\u001b[33mYou are using pip version 19.0.3, however version 19.3.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3 install sklearn\n",
    "# seaborn\n",
    "# stats\n",
    "# scipy\n",
    "# !pip3 install umap-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting seaborn\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a8/76/220ba4420459d9c4c9c9587c6ce607bf56c25b3d3d2de62056efe482dadc/seaborn-0.9.0-py3-none-any.whl (208kB)\n",
      "\u001b[K    100% |████████████████████████████████| 215kB 1.6MB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: scipy>=0.14.0 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from seaborn) (1.3.1)\n",
      "Requirement already satisfied: pandas>=0.15.2 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from seaborn) (0.25.1)\n",
      "Requirement already satisfied: matplotlib>=1.4.3 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from seaborn) (3.1.1)\n",
      "Requirement already satisfied: numpy>=1.9.3 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from seaborn) (1.17.0)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from pandas>=0.15.2->seaborn) (2.8.0)\n",
      "Requirement already satisfied: pytz>=2017.2 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from pandas>=0.15.2->seaborn) (2019.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from matplotlib>=1.4.3->seaborn) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from matplotlib>=1.4.3->seaborn) (1.1.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from matplotlib>=1.4.3->seaborn) (2.4.2)\n",
      "Requirement already satisfied: six>=1.5 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from python-dateutil>=2.6.1->pandas>=0.15.2->seaborn) (1.12.0)\n",
      "Requirement already satisfied: setuptools in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from kiwisolver>=1.0.1->matplotlib>=1.4.3->seaborn) (40.8.0)\n",
      "Installing collected packages: seaborn\n",
      "Successfully installed seaborn-0.9.0\n",
      "\u001b[33mYou are using pip version 19.0.3, however version 19.3.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Collecting stats\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/87/43/f2d8d8e2660740ecca9c0fab85a07bc02da27d1fcc5071ee481082888720/stats-0.1.2a.tar.gz (127kB)\n",
      "\u001b[K    100% |████████████████████████████████| 133kB 2.2MB/s ta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: stats\n",
      "  Running setup.py install for stats ... \u001b[?25ldone\n",
      "\u001b[?25hSuccessfully installed stats-0.1.2a0\n",
      "\u001b[33mYou are using pip version 19.0.3, however version 19.3.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: scipy in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (1.3.1)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from scipy) (1.17.0)\n",
      "\u001b[33mYou are using pip version 19.0.3, however version 19.3.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Collecting umap-learn\n",
      "Requirement already satisfied: numpy>=1.13 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from umap-learn) (1.17.0)\n",
      "Collecting numba>=0.37 (from umap-learn)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8c/2e/a650b9013d692845e619e666f6a16ce1a4f44a47254c333214290a8611ae/numba-0.47.0-cp37-cp37m-macosx_10_9_x86_64.whl (2.0MB)\n",
      "\u001b[K    100% |████████████████████████████████| 2.0MB 6.7MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: scikit-learn>=0.16 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from umap-learn) (0.22.1)\n",
      "Requirement already satisfied: scipy>=0.19 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from umap-learn) (1.3.1)\n",
      "Requirement already satisfied: setuptools in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from numba>=0.37->umap-learn) (40.8.0)\n",
      "Collecting llvmlite>=0.31.0dev0 (from numba>=0.37->umap-learn)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6d/81/3ef1bf97adac4f200a7ff61a6c0be52f7eab9c4f8807edb494b72ec2674a/llvmlite-0.31.0-cp37-cp37m-macosx_10_9_x86_64.whl (15.9MB)\n",
      "\u001b[K    100% |████████████████████████████████| 15.9MB 1.2MB/s eta 0:00:01  2% |▉                               | 399kB 8.5MB/s eta 0:00:02    5% |█▉                              | 890kB 10.3MB/s eta 0:00:02    40% |█████████████                   | 6.5MB 2.8MB/s eta 0:00:04\n",
      "\u001b[?25hRequirement already satisfied: joblib>=0.11 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from scikit-learn>=0.16->umap-learn) (0.14.1)\n",
      "Installing collected packages: llvmlite, numba, umap-learn\n",
      "Successfully installed llvmlite-0.31.0 numba-0.47.0 umap-learn-0.3.10\n",
      "\u001b[33mYou are using pip version 19.0.3, however version 19.3.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Collecting xgboost\n",
      "Requirement already satisfied: scipy in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from xgboost) (1.3.1)\n",
      "Requirement already satisfied: numpy in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from xgboost) (1.17.0)\n",
      "Installing collected packages: xgboost\n",
      "Successfully installed xgboost-0.90\n",
      "\u001b[33mYou are using pip version 19.0.3, however version 19.3.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Collecting tensorflow\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/35/55/a0dbd642e68e68f3e309d1413abdc0a7aa7e1534c79c0fc2501defb864ac/tensorflow-2.1.0-cp37-cp37m-macosx_10_11_x86_64.whl (120.8MB)\n",
      "\u001b[K    100% |████████████████████████████████| 120.8MB 174kB/s ta 0:00:011 1% |▍                               | 1.6MB 15.2MB/s eta 0:00:08    8% |██▋                             | 10.0MB 4.1MB/s eta 0:00:27    20% |██████▍                         | 24.3MB 14.3MB/s eta 0:00:07    26% |████████▍                       | 31.9MB 12.1MB/s eta 0:00:08    36% |███████████▋                    | 43.7MB 28.1MB/s eta 0:00:03    38% |████████████▌                   | 47.0MB 2.6MB/s eta 0:00:29    41% |█████████████▍                  | 50.5MB 8.0MB/s eta 0:00:09    44% |██████████████▏                 | 53.3MB 16.2MB/s eta 0:00:05    68% |█████████████████████▉          | 82.3MB 6.1MB/s eta 0:00:07    80% |█████████████████████████▊      | 97.2MB 5.4MB/s eta 0:00:05    94% |██████████████████████████████▏ | 114.0MB 4.5MB/s eta 0:00:02    96% |██████████████████████████████▉ | 116.6MB 2.9MB/s eta 0:00:02\n",
      "\u001b[?25hCollecting gast==0.2.2 (from tensorflow)\n",
      "Collecting keras-applications>=1.0.8 (from tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl\n",
      "Collecting opt-einsum>=2.3.2 (from tensorflow)\n",
      "Requirement already satisfied: six>=1.12.0 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from tensorflow) (1.12.0)\n",
      "Collecting absl-py>=0.7.0 (from tensorflow)\n",
      "Collecting wheel>=0.26; python_version >= \"3\" (from tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/00/83/b4a77d044e78ad1a45610eb88f745be2fd2c6d658f9798a15e384b7d57c9/wheel-0.33.6-py2.py3-none-any.whl\n",
      "Requirement already satisfied: numpy<2.0,>=1.16.0 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from tensorflow) (1.17.0)\n",
      "Collecting tensorflow-estimator<2.2.0,>=2.1.0rc0 (from tensorflow)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/18/90/b77c328a1304437ab1310b463e533fa7689f4bfc41549593056d812fab8e/tensorflow_estimator-2.1.0-py2.py3-none-any.whl (448kB)\n",
      "\u001b[K    100% |████████████████████████████████| 450kB 9.0MB/s ta 0:00:011\n",
      "\u001b[?25hCollecting keras-preprocessing>=1.1.0 (from tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/28/6a/8c1f62c37212d9fc441a7e26736df51ce6f0e38455816445471f10da4f0a/Keras_Preprocessing-1.1.0-py2.py3-none-any.whl\n",
      "Collecting google-pasta>=0.1.6 (from tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/c3/fd/1e86bc4837cc9a3a5faf3db9b1854aa04ad35b5f381f9648fbe81a6f94e4/google_pasta-0.1.8-py3-none-any.whl\n",
      "Collecting tensorboard<2.2.0,>=2.1.0 (from tensorflow)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/40/23/53ffe290341cd0855d595b0a2e7485932f473798af173bbe3a584b99bb06/tensorboard-2.1.0-py3-none-any.whl (3.8MB)\n",
      "\u001b[K    100% |████████████████████████████████| 3.8MB 2.1MB/s ta 0:00:011\n",
      "\u001b[?25hCollecting scipy==1.4.1; python_version >= \"3\" (from tensorflow)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/85/7a/ae480be23b768910a9327c33517ced4623ba88dc035f9ce0206657c353a9/scipy-1.4.1-cp37-cp37m-macosx_10_6_intel.whl (28.4MB)\n",
      "\u001b[K    100% |████████████████████████████████| 28.4MB 706kB/s ta 0:00:011  8% |██▉                             | 2.5MB 2.2MB/s eta 0:00:12\n",
      "\u001b[?25hCollecting protobuf>=3.8.0 (from tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/2d/09/176fcab8aab35065e9f973c0ef093e8e296fb4d8d4e3ef2ed4fd2e6ff2f2/protobuf-3.11.2-cp37-cp37m-macosx_10_9_x86_64.whl\n",
      "Collecting termcolor>=1.1.0 (from tensorflow)\n",
      "Collecting grpcio>=1.8.6 (from tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/df/f1/98449d2c173c6324220ab1672203ad09ac7345f023dc62eb0786ad2a0df6/grpcio-1.26.0-cp37-cp37m-macosx_10_9_x86_64.whl\n",
      "Collecting wrapt>=1.11.1 (from tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/23/84/323c2415280bc4fc880ac5050dddfb3c8062c2552b34c2e512eb4aa68f79/wrapt-1.11.2.tar.gz\n",
      "Collecting astor>=0.6.0 (from tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/c3/88/97eef84f48fa04fbd6750e62dcceafba6c63c81b7ac1420856c8dcc0a3f9/astor-0.8.1-py2.py3-none-any.whl\n",
      "Collecting h5py (from keras-applications>=1.0.8->tensorflow)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1a/8b/4d01ae9a9d50a0bcc7b0b9aae41785d8d9de6fa9bba04dc20b1582181d2d/h5py-2.10.0-cp37-cp37m-macosx_10_6_intel.whl (3.0MB)\n",
      "\u001b[K    100% |████████████████████████████████| 3.0MB 3.8MB/s ta 0:00:011\n",
      "\u001b[?25hCollecting werkzeug>=0.11.15 (from tensorboard<2.2.0,>=2.1.0->tensorflow)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ce/42/3aeda98f96e85fd26180534d36570e4d18108d62ae36f87694b476b83d6f/Werkzeug-0.16.0-py2.py3-none-any.whl (327kB)\n",
      "\u001b[K    100% |████████████████████████████████| 327kB 2.7MB/s ta 0:00:011\n",
      "\u001b[?25hCollecting markdown>=2.6.8 (from tensorboard<2.2.0,>=2.1.0->tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/c0/4e/fd492e91abdc2d2fcb70ef453064d980688762079397f779758e055f6575/Markdown-3.1.1-py2.py3-none-any.whl\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1 (from tensorboard<2.2.0,>=2.1.0->tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/7b/b8/88def36e74bee9fce511c9519571f4e485e890093ab7442284f4ffaef60b/google_auth_oauthlib-0.4.1-py2.py3-none-any.whl\n",
      "Collecting google-auth<2,>=1.6.3 (from tensorboard<2.2.0,>=2.1.0->tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/36/f8/84b5771faec3eba9fe0c91c8c5896364a8ba08852c0dea5ad2025026dd95/google_auth-1.10.0-py2.py3-none-any.whl\n",
      "Collecting requests<3,>=2.21.0 (from tensorboard<2.2.0,>=2.1.0->tensorflow)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/51/bd/23c926cd341ea6b7dd0b2a00aba99ae0f828be89d72b2190f27c11d4b7fb/requests-2.22.0-py2.py3-none-any.whl (57kB)\n",
      "\u001b[K    100% |████████████████████████████████| 61kB 6.6MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting setuptools>=41.0.0 (from tensorboard<2.2.0,>=2.1.0->tensorflow)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/af/e7/02db816dc88c598281bacebbb7ccf2c9f1a6164942e88f1a0fded8643659/setuptools-45.0.0-py2.py3-none-any.whl (583kB)\n",
      "\u001b[K    100% |████████████████████████████████| 593kB 7.5MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting requests-oauthlib>=0.7.0 (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/a3/12/b92740d845ab62ea4edf04d2f4164d82532b5a0b03836d4d4e71c6f3d379/requests_oauthlib-1.3.0-py2.py3-none-any.whl\n",
      "Collecting cachetools<5.0,>=2.0.0 (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/08/6a/abf83cb951617793fd49c98cb9456860f5df66ff89883c8660aa0672d425/cachetools-4.0.0-py3-none-any.whl\n",
      "Collecting pyasn1-modules>=0.2.1 (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/95/de/214830a981892a3e286c3794f41ae67a4495df1108c3da8a9f62159b9a9d/pyasn1_modules-0.2.8-py2.py3-none-any.whl (155kB)\n",
      "\u001b[K    100% |████████████████████████████████| 163kB 11.2MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting rsa<4.1,>=3.1.4 (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/02/e5/38518af393f7c214357079ce67a317307936896e961e35450b70fad2a9cf/rsa-4.0-py2.py3-none-any.whl\n",
      "Collecting certifi>=2017.4.17 (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b9/63/df50cac98ea0d5b006c55a399c3bf1db9da7b5a24de7890bc9cfd5dd9e99/certifi-2019.11.28-py2.py3-none-any.whl (156kB)\n",
      "\u001b[K    100% |████████████████████████████████| 163kB 5.2MB/s ta 0:00:011\n",
      "\u001b[?25hCollecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b4/40/a9837291310ee1ccc242ceb6ebfd9eb21539649f193a7c8c86ba15b98539/urllib3-1.25.7-py2.py3-none-any.whl (125kB)\n",
      "\u001b[K    100% |████████████████████████████████| 133kB 12.0MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting chardet<3.1.0,>=3.0.2 (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bc/a9/01ffebfb562e4274b6487b4bb1ddec7ca55ec7510b22e4c51f14098443b8/chardet-3.0.4-py2.py3-none-any.whl (133kB)\n",
      "\u001b[K    100% |████████████████████████████████| 143kB 7.5MB/s ta 0:00:011\n",
      "\u001b[?25hCollecting idna<2.9,>=2.5 (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/14/2c/cd551d81dbe15200be1cf41cd03869a46fe7226e7450af7a6545bfc474c9/idna-2.8-py2.py3-none-any.whl (58kB)\n",
      "\u001b[K    100% |████████████████████████████████| 61kB 9.1MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting oauthlib>=3.0.0 (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/05/57/ce2e7a8fa7c0afb54a0581b14a65b56e62b5759dbc98e80627142b8a3704/oauthlib-3.1.0-py2.py3-none-any.whl\n",
      "Collecting pyasn1<0.5.0,>=0.4.6 (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/62/1e/a94a8d635fa3ce4cfc7f506003548d0a2447ae76fd5ca53932970fe3053f/pyasn1-0.4.8-py2.py3-none-any.whl\n",
      "Installing collected packages: gast, h5py, keras-applications, opt-einsum, absl-py, wheel, tensorflow-estimator, keras-preprocessing, google-pasta, werkzeug, setuptools, protobuf, markdown, cachetools, pyasn1, pyasn1-modules, rsa, google-auth, certifi, urllib3, chardet, idna, requests, oauthlib, requests-oauthlib, google-auth-oauthlib, grpcio, tensorboard, scipy, termcolor, wrapt, astor, tensorflow\n",
      "  Found existing installation: setuptools 40.8.0\n",
      "    Uninstalling setuptools-40.8.0:\n",
      "      Successfully uninstalled setuptools-40.8.0\n",
      "  Found existing installation: scipy 1.3.1\n",
      "    Uninstalling scipy-1.3.1:\n",
      "      Successfully uninstalled scipy-1.3.1\n",
      "  Running setup.py install for wrapt ... \u001b[?25ldone\n",
      "\u001b[?25hSuccessfully installed absl-py-0.9.0 astor-0.8.1 cachetools-4.0.0 certifi-2019.11.28 chardet-3.0.4 gast-0.2.2 google-auth-1.10.0 google-auth-oauthlib-0.4.1 google-pasta-0.1.8 grpcio-1.26.0 h5py-2.10.0 idna-2.8 keras-applications-1.0.8 keras-preprocessing-1.1.0 markdown-3.1.1 oauthlib-3.1.0 opt-einsum-3.1.0 protobuf-3.11.2 pyasn1-0.4.8 pyasn1-modules-0.2.8 requests-2.22.0 requests-oauthlib-1.3.0 rsa-4.0 scipy-1.4.1 setuptools-45.0.0 tensorboard-2.1.0 tensorflow-2.1.0 tensorflow-estimator-2.1.0 termcolor-1.1.0 urllib3-1.25.7 werkzeug-0.16.0 wheel-0.33.6 wrapt-1.11.2\n",
      "\u001b[33mYou are using pip version 19.0.3, however version 19.3.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Collecting pip\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/00/b6/9cfa56b4081ad13874b0c6f96af8ce16cfbc1cb06bedf8e9164ce5551ec1/pip-19.3.1-py2.py3-none-any.whl (1.4MB)\n",
      "\u001b[K    100% |████████████████████████████████| 1.4MB 4.8MB/s ta 0:00:011\n",
      "\u001b[?25hInstalling collected packages: pip\n",
      "  Found existing installation: pip 19.0.3\n",
      "    Uninstalling pip-19.0.3:\n",
      "      Successfully uninstalled pip-19.0.3\n",
      "Successfully installed pip-19.3.1\n"
     ]
    }
   ],
   "source": [
    "!pip3 install seaborn\n",
    "!pip3 install stats\n",
    "!pip3 install scipy\n",
    "!pip3 install umap-learn\n",
    "!pip3 install xgboost\n",
    "!pip3 install tensorflow\n",
    "!pip3 install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: Could not find a version that satisfies the requirement PIL (from versions: none)\u001b[0m\r\n",
      "\u001b[31mERROR: No matching distribution found for PIL\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip3 install PIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package            Version\n",
      "------------------ -------\n",
      "appnope            0.1.0  \n",
      "attrs              19.1.0 \n",
      "backcall           0.1.0  \n",
      "bleach             3.1.0  \n",
      "cycler             0.10.0 \n",
      "decorator          4.4.0  \n",
      "defusedxml         0.6.0  \n",
      "entrypoints        0.3    \n",
      "ipykernel          5.1.2  \n",
      "ipython            7.7.0  \n",
      "ipython-genutils   0.2.0  \n",
      "ipywidgets         7.5.1  \n",
      "jedi               0.15.1 \n",
      "Jinja2             2.10.1 \n",
      "jsonschema         3.0.2  \n",
      "jupyter            1.0.0  \n",
      "jupyter-client     5.3.1  \n",
      "jupyter-console    6.0.0  \n",
      "jupyter-core       4.5.0  \n",
      "kiwisolver         1.1.0  \n",
      "MarkupSafe         1.1.1  \n",
      "matplotlib         3.1.1  \n",
      "mistune            0.8.4  \n",
      "nbconvert          5.6.0  \n",
      "nbformat           4.4.0  \n",
      "notebook           6.0.1  \n",
      "numpy              1.17.0 \n",
      "pandas             0.25.1 \n",
      "pandocfilters      1.4.2  \n",
      "parso              0.5.1  \n",
      "pexpect            4.7.0  \n",
      "pickleshare        0.7.5  \n",
      "pip                19.0.3 \n",
      "prometheus-client  0.7.1  \n",
      "prompt-toolkit     2.0.9  \n",
      "ptyprocess         0.6.0  \n",
      "Pygments           2.4.2  \n",
      "pyparsing          2.4.2  \n",
      "pyrsistent         0.15.4 \n",
      "python-dateutil    2.8.0  \n",
      "pytz               2019.2 \n",
      "pyzmq              18.1.0 \n",
      "qtconsole          4.5.4  \n",
      "scipy              1.3.1  \n",
      "Send2Trash         1.5.0  \n",
      "setuptools         40.8.0 \n",
      "six                1.12.0 \n",
      "terminado          0.8.2  \n",
      "testpath           0.4.2  \n",
      "tornado            6.0.3  \n",
      "traitlets          4.3.2  \n",
      "wcwidth            0.1.7  \n",
      "webencodings       0.5.1  \n",
      "widgetsnbextension 3.5.1  \n",
      "\u001b[33mYou are using pip version 19.0.3, however version 19.3.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('/Users/sophiaperides/Desktop/Thinkful')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.datasets import fetch_openml\n",
    "%matplotlib inline\n",
    "from datetime import datetime, timedelta\n",
    "import re\n",
    "\n",
    "\n",
    "from matplotlib import image\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.stats.mstats import winsorize\n",
    "from sklearn.preprocessing import normalize\n",
    "import scipy.stats as stats\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn import ensemble\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "import umap\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn import datasets, metrics\n",
    "from sklearn.cluster import MiniBatchKMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fifa = pd.read_csv('2019fifadata.csv')\n",
    "fifa = pd.DataFrame(fifa)\n",
    "print(fifa.columns)\n",
    "print(fifa.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction \n",
    "We'll look at how to predict a player's wage using the FIFA dataset . I'll remove columns that don't provide useful information (Unnamed:0, ID, Name, Photo, Flag, Club Logo, and Real Face). As we have 18,207 entries and multiple columns are missing 48 values, my instinct is that these rows are missing information in these columns. As such, I'll remove rows missing information in 48 cells.\n",
    "\n",
    "Columns LS through RB are missing values in over two thousand cells and while it's not obvious what each variable represents (there's no information on the Kaggle page and it's not immediately clear on the sofifa.com page), they could contain valuable information. Each value is a string of a number plus another number, so I'm going to strip the addition sign and the second number, and populate these cells with the first number. I will then fill the missing values with the mean.\n",
    "\n",
    "Joined, Jersey Number, Loaned From, and Release Clause\n",
    "\n",
    "After these updates, we're still missing values in Club, Contract Valid Until, and Position columns. While I could go through and find the information on each of these, I don't think that would be a great use of time for this project, so I'm going to drop rows for which there aren't values for Club/Contract valid until and hope this takes care of rows lacking a value in Position as well. Finally, Club is a categorical variable with over 650 categories, which will be a pain to create/utilize dummies for, so I will remove this column.\n",
    "\n",
    "We've managed to clean up our data and keep over 98% of the rows. If we have trouble coming up with a model, we'll look at adding back some columns we've removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'fifa' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-8943a1aa6726>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfifa\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfifa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthresh\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m48\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m variables = ['LS', 'ST', 'RS', 'LW', 'LF', 'CF', 'RF', 'RW',\n\u001b[1;32m      4\u001b[0m        \u001b[0;34m'LAM'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'CAM'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'RAM'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'LM'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'LCM'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'CM'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'RCM'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'RM'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'LWB'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'LDM'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m        'CDM', 'RDM', 'RWB', 'LB', 'LCB', 'CB', 'RCB', 'RB']\n",
      "\u001b[0;31mNameError\u001b[0m: name 'fifa' is not defined"
     ]
    }
   ],
   "source": [
    "fifa = fifa.dropna(thresh=48, axis=0)\n",
    "\n",
    "variables = ['LS', 'ST', 'RS', 'LW', 'LF', 'CF', 'RF', 'RW',\n",
    "       'LAM', 'CAM', 'RAM', 'LM', 'LCM', 'CM', 'RCM', 'RM', 'LWB', 'LDM',\n",
    "       'CDM', 'RDM', 'RWB', 'LB', 'LCB', 'CB', 'RCB', 'RB']\n",
    "\n",
    "data = fifa[variables]\n",
    "df = data.astype(str).apply(lambda x: x.str.split('+').str[0])\n",
    "df = df.astype(float)\n",
    "df.fillna(df.mean(), inplace=True)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fifa = fifa.drop(columns=['LS', 'ST', 'RS', 'LW', 'LF', 'CF', 'RF', 'RW',\n",
    "       'LAM', 'CAM', 'RAM', 'LM', 'LCM', 'CM', 'RCM', 'RM', 'LWB', 'LDM',\n",
    "       'CDM', 'RDM', 'RWB', 'LB', 'LCB', 'CB', 'RCB', 'RB'])\n",
    "\n",
    "fifa = pd.concat([fifa, df], axis=1)\n",
    "pd.options.display.max_columns = None\n",
    "fifa.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fifa = fifa.drop(['Unnamed: 0', 'ID', 'Name', 'Photo', 'Flag', 'Club Logo', 'Real Face', 'Joined', 'Loaned From'], axis=1)\n",
    "\n",
    "fifa.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fifa = fifa[pd.notnull(fifa['Position'])]\n",
    "fifa = fifa.drop(['Club', 'Contract Valid Until'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Update Variables\n",
    "There are quite a few columns that are currently being read as objects but should be integers or floats. I'll remove the €, K, and M from the Wage and Value columns and update the values as necessary. I will update the Height column into inches and remove the lbs from the Weight column. I'll perform one hot encoding on the remaining values (Nationality, Preferred Foot Work Rate, Body Type, and Position) to obtain dummies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fifa.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fifa['Value'] = fifa['Value'].str.replace('€', '')\n",
    "fifa['Value'] = fifa['Value'].str.replace('.', '')\n",
    "fifa['Value'] = fifa['Value'].apply(lambda row: row.replace('K', '000') if 'K' in row else row.replace('M', '000000')).astype(float)\n",
    "\n",
    "fifa['Wage'] = fifa['Wage'].str.replace('€', '')\n",
    "fifa['Wage'] = fifa['Wage'].str.replace('.', '')\n",
    "fifa['Wage'] = fifa['Wage'].apply(lambda row: row.replace('K', '000') if 'K' in row else row.replace('M', '000000')).astype(float)\n",
    "fifa.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fifa['Release Clause'] = fifa['Release Clause'].str[1:]\n",
    "print(fifa[:5]['Release Clause'])\n",
    "fifa.loc[fifa['Release Clause'].str.contains('M', na=False), 'Release Clause'] = fifa[fifa['Release Clause'].str.contains('M', na=False)]['Release Clause'].str[:-1].astype(float)*1000000\n",
    "fifa.loc[fifa['Release Clause'].str.contains('K', na=False), 'Release Clause'] = fifa[fifa['Release Clause'].str.contains('K', na=False)]['Release Clause'].str[:-1].astype(float)*1000\n",
    "print(fifa[:5]['Release Clause'])\n",
    "fifa['Release Clause'].isnull().value_counts()\n",
    "fifa['Release Clause'].fillna(fifa['Release Clause'].mean(), inplace=True)\n",
    "print(fifa.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_ht(ht):\n",
    "    # format: 7' 0.0\"\n",
    "    feet = float(ht[0])\n",
    "    inches = float(ht[2:])\n",
    "    return 12*feet + inches\n",
    "\n",
    "\n",
    "fifa['Height'] = fifa['Height'].apply(lambda x: parse_ht(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fifa['Weight'] = fifa['Weight'].apply(lambda x: float(str(x).replace('lbs', '')))\n",
    "pd.options.display.max_columns = None\n",
    "fifa.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fifa = pd.concat([fifa, pd.get_dummies(fifa['Nationality'])], axis=1)\n",
    "fifa = pd.concat([fifa, pd.get_dummies(fifa[\"Preferred Foot\"])], axis=1)\n",
    "fifa = pd.concat([fifa, pd.get_dummies(fifa[\"Work Rate\"])], axis=1)\n",
    "fifa = pd.concat([fifa, pd.get_dummies(fifa[\"Body Type\"])], axis=1)\n",
    "fifa = pd.concat([fifa, pd.get_dummies(fifa[\"Position\"])], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_mat = np.abs((fifa.corr().loc[:, ['Wage']])).sort_values(by='Wage', ascending=False)\n",
    "corr_mat[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
