{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a multi-layer perceptron neural network model to predict on a labeled dataset of your choosing. Compare this model to either a boosted tree or a random forest model and describe the relative tradeoffs between complexity and accuracy. Be sure to vary the hyperparameters of your MLP!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('/Users/sophiaperides/Desktop/Thinkful')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.datasets import fetch_openml\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn import ensemble\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Breast Cancer Columns\n",
      "Index(['id', 'diagnosis', 'radius_mean', 'texture_mean', 'perimeter_mean',\n",
      "       'area_mean', 'smoothness_mean', 'compactness_mean', 'concavity_mean',\n",
      "       'concave points_mean', 'symmetry_mean', 'fractal_dimension_mean',\n",
      "       'radius_se', 'texture_se', 'perimeter_se', 'area_se', 'smoothness_se',\n",
      "       'compactness_se', 'concavity_se', 'concave points_se', 'symmetry_se',\n",
      "       'fractal_dimension_se', 'radius_worst', 'texture_worst',\n",
      "       'perimeter_worst', 'area_worst', 'smoothness_worst',\n",
      "       'compactness_worst', 'concavity_worst', 'concave points_worst',\n",
      "       'symmetry_worst', 'fractal_dimension_worst'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print('Breast Cancer Columns')\n",
    "br = pd.read_csv('breast_cancer.csv')\n",
    "br = pd.DataFrame(br)\n",
    "print(br.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 569 entries, 0 to 568\n",
      "Data columns (total 32 columns):\n",
      "id                         569 non-null int64\n",
      "diagnosis                  569 non-null object\n",
      "radius_mean                569 non-null float64\n",
      "texture_mean               569 non-null float64\n",
      "perimeter_mean             569 non-null float64\n",
      "area_mean                  569 non-null float64\n",
      "smoothness_mean            569 non-null float64\n",
      "compactness_mean           569 non-null float64\n",
      "concavity_mean             569 non-null float64\n",
      "concave points_mean        569 non-null float64\n",
      "symmetry_mean              569 non-null float64\n",
      "fractal_dimension_mean     569 non-null float64\n",
      "radius_se                  569 non-null float64\n",
      "texture_se                 569 non-null float64\n",
      "perimeter_se               569 non-null float64\n",
      "area_se                    569 non-null float64\n",
      "smoothness_se              569 non-null float64\n",
      "compactness_se             569 non-null float64\n",
      "concavity_se               569 non-null float64\n",
      "concave points_se          569 non-null float64\n",
      "symmetry_se                569 non-null float64\n",
      "fractal_dimension_se       569 non-null float64\n",
      "radius_worst               569 non-null float64\n",
      "texture_worst              569 non-null float64\n",
      "perimeter_worst            569 non-null float64\n",
      "area_worst                 569 non-null float64\n",
      "smoothness_worst           569 non-null float64\n",
      "compactness_worst          569 non-null float64\n",
      "concavity_worst            569 non-null float64\n",
      "concave points_worst       569 non-null float64\n",
      "symmetry_worst             569 non-null float64\n",
      "fractal_dimension_worst    569 non-null float64\n",
      "dtypes: float64(30), int64(1), object(1)\n",
      "memory usage: 142.3+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "B    357\n",
       "M    212\n",
       "Name: diagnosis, dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "br.info()\n",
    "br.diagnosis.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = br.diagnosis\n",
    "X = br.drop(columns=['diagnosis', 'id'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Models\n",
    "\n",
    "## Multiple Layer Perceptrons\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP Score:  0.9367311072056239\n",
      "Cross Validation Scores:  [0.87931034 0.89655172 0.92982456 0.94736842 0.92982456 0.9122807\n",
      " 0.94736842 0.92857143 0.76785714 0.875     ]\n",
      "Mean Cross Validation Score:  0.923069527266442\n"
     ]
    }
   ],
   "source": [
    "mlp = MLPClassifier(hidden_layer_sizes=(1000,))\n",
    "mlp.fit(X, y)\n",
    "print('MLP Score: ', mlp.score(X, y))\n",
    "      \n",
    "print('Cross Validation Scores: ', cross_val_score(mlp, X, y, cv=10))\n",
    "print('Mean Cross Validation Score: ', cross_val_score(mlp, X, y, cv=10).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP Score:  0.9332161687170475\n",
      "Cross Validation Score:  [0.9137931  0.84482759 0.92982456 0.94736842 0.9122807  0.87719298\n",
      " 0.94736842 0.91071429 0.92857143 0.91071429]\n",
      "Mean Cross Validation Score:  0.9122655777374471\n"
     ]
    }
   ],
   "source": [
    "mlp = MLPClassifier(hidden_layer_sizes=(100, 100))\n",
    "mlp.fit(X, y)\n",
    "print('MLP Score: ', mlp.score(X, y))\n",
    "\n",
    "cross_val = cross_val_score(mlp, X, y, cv=10)\n",
    "print('Cross Validation Score: ', cross_val)\n",
    "print('Mean Cross Validation Score: ', cross_val.mean())\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP Score:  0.9209138840070299\n",
      "Cross Validation Score:  [0.9137931  0.9137931  0.9122807  0.94736842 0.9122807  0.92982456\n",
      " 0.85964912 0.92857143 0.92857143 0.94642857]\n",
      "Mean Cross Validation Score:  0.919256114423991\n"
     ]
    }
   ],
   "source": [
    "mlp = MLPClassifier(hidden_layer_sizes=(100, 100, 100))\n",
    "mlp.fit(X, y)\n",
    "print('MLP Score: ', mlp.score(X, y))\n",
    "      \n",
    "cross_val = cross_val_score(mlp, X, y, cv=10)\n",
    "print('Cross Validation Score: ', cross_val)\n",
    "print('Mean Cross Validation Score: ', cross_val.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP Score:  0.9279437609841827\n",
      "Cross Validation Score:  [0.93103448 0.93103448 0.89473684 0.94736842 0.9122807  0.92982456\n",
      " 0.9122807  0.92857143 0.85714286 0.875     ]\n",
      "Mean Cross Validation Score:  0.9119274479301703\n"
     ]
    }
   ],
   "source": [
    "mlp = MLPClassifier(hidden_layer_sizes=(50, 50))\n",
    "mlp.fit(X, y)\n",
    "print('MLP Score: ', mlp.score(X, y))\n",
    "      \n",
    "cross_val = cross_val_score(mlp, X, y, cv=10)\n",
    "print('Cross Validation Score: ', cross_val)\n",
    "print('Mean Cross Validation Score: ', cross_val.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Score:  [0.94827586 0.89655172 0.92982456 0.92982456 0.87719298 0.92982456\n",
      " 0.94736842 0.91071429 0.82142857 0.82142857]\n",
      "Mean Cross Validation Score:  0.9012434102497624\n"
     ]
    }
   ],
   "source": [
    "mlp = MLPClassifier(hidden_layer_sizes=(1000,))\n",
    "mlp.fit(X, y)\n",
    "cross_val = cross_val_score(mlp, X, y, cv=10)\n",
    "print('Cross Validation Score: ', cross_val)\n",
    "print('Mean Cross Validation Score: ', cross_val.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP Score:  0.9279437609841827\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Score:  [0.93103448 0.84482759 0.9122807  0.94736842 0.92982456 0.89473684\n",
      " 0.94736842 0.91071429 0.85714286 0.91071429]\n",
      "Mean Cross Validation Score:  0.9086012444905368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "mlp = MLPClassifier(hidden_layer_sizes=(10, 10))\n",
    "mlp.fit(X, y)\n",
    "print('MLP Score: ', mlp.score(X, y))\n",
    "      \n",
    "cross_val = cross_val_score(mlp, X, y, cv=10)\n",
    "print('Cross Validation Score: ', cross_val)\n",
    "print('Mean Cross Validation Score: ', cross_val.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 108 candidates, totalling 1080 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   16.3s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:   35.2s\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 792 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=-1)]: Done 1080 out of 1080 | elapsed:  3.2min finished\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py:813: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters for the best Multiple Layer Perceptron Classifier:  MLPClassifier(activation='tanh', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "              hidden_layer_sizes=(50, 10), learning_rate='constant',\n",
      "              learning_rate_init=0.001, max_iter=300, momentum=0.9,\n",
      "              n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
      "              random_state=None, shuffle=True, solver='adam', tol=0.0001,\n",
      "              validation_fraction=0.1, verbose=False, warm_start=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "mlp_gsc = GridSearchCV(\n",
    "        estimator=MLPClassifier(),\n",
    "        param_grid={\n",
    "            'hidden_layer_sizes': [(20, 20), (10), (50, 10)],\n",
    "            'activation': ['identity', 'logistic', 'tanh', 'relu'],\n",
    "            'learning_rate': ['constant', 'invscaling', 'adaptive'],\n",
    "            'max_iter': [100, 200, 300]\n",
    "        },\n",
    "        cv=10, scoring='accuracy', verbose=1, n_jobs=-1)\n",
    "\n",
    "mlp_gsc.fit(X_top_features, y)\n",
    "best_params = mlp_gsc.best_params_\n",
    "# svr_gsc.best_estimator_\n",
    "best_mlp = MLPClassifier(hidden_layer_sizes=best_params['hidden_layer_sizes'], activation=best_params[\"activation\"],\n",
    "                                         learning_rate=best_params[\"learning_rate\"], max_iter=best_params[\"max_iter\"],\n",
    "                                         verbose=False)\n",
    "\n",
    "print('Parameters for the best Multiple Layer Perceptron Classifier: ', best_mlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP Score:  0.9543057996485061\n",
      "Cross Validation Score:  [0.94827586 0.93103448 0.9122807  0.92982456 0.98245614 0.9122807\n",
      " 0.9122807  0.89285714 0.875      0.92857143]\n",
      "Mean Cross Validation Score:  0.9224861723273703\n"
     ]
    }
   ],
   "source": [
    "best_mlp.fit(X, y)\n",
    "print('MLP Score: ', best_mlp.score(X, y))\n",
    "      \n",
    "cross_val = cross_val_score(best_mlp, X, y, cv=10)\n",
    "print('Cross Validation Score: ', cross_val)\n",
    "print('Mean Cross Validation Score: ', cross_val.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 569 entries, 0 to 568\n",
      "Data columns (total 32 columns):\n",
      "id                         569 non-null int64\n",
      "diagnosis                  569 non-null int64\n",
      "radius_mean                569 non-null float64\n",
      "texture_mean               569 non-null float64\n",
      "perimeter_mean             569 non-null float64\n",
      "area_mean                  569 non-null float64\n",
      "smoothness_mean            569 non-null float64\n",
      "compactness_mean           569 non-null float64\n",
      "concavity_mean             569 non-null float64\n",
      "concave points_mean        569 non-null float64\n",
      "symmetry_mean              569 non-null float64\n",
      "fractal_dimension_mean     569 non-null float64\n",
      "radius_se                  569 non-null float64\n",
      "texture_se                 569 non-null float64\n",
      "perimeter_se               569 non-null float64\n",
      "area_se                    569 non-null float64\n",
      "smoothness_se              569 non-null float64\n",
      "compactness_se             569 non-null float64\n",
      "concavity_se               569 non-null float64\n",
      "concave points_se          569 non-null float64\n",
      "symmetry_se                569 non-null float64\n",
      "fractal_dimension_se       569 non-null float64\n",
      "radius_worst               569 non-null float64\n",
      "texture_worst              569 non-null float64\n",
      "perimeter_worst            569 non-null float64\n",
      "area_worst                 569 non-null float64\n",
      "smoothness_worst           569 non-null float64\n",
      "compactness_worst          569 non-null float64\n",
      "concavity_worst            569 non-null float64\n",
      "concave points_worst       569 non-null float64\n",
      "symmetry_worst             569 non-null float64\n",
      "fractal_dimension_worst    569 non-null float64\n",
      "dtypes: float64(30), int64(2)\n",
      "memory usage: 142.3 KB\n"
     ]
    }
   ],
   "source": [
    "# Updating the target to a numerical variable.\n",
    "br['diagnosis'] = br['diagnosis'].apply(lambda x: 1 if 'M' else 0)\n",
    "br.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Score:  [0.98275862 0.9137931  0.94736842 0.96491228 0.98245614 0.98245614\n",
      " 0.92982456 0.98214286 0.96428571 1.        ]\n",
      "Mean Cross Validation Score:  0.9649997839426151\n",
      "\n",
      " Feature Importances:  [0.02429854 0.01419575 0.0539929  0.04540104 0.00795465 0.00345576\n",
      " 0.07186229 0.08852713 0.00558817 0.0021412  0.01900904 0.00490146\n",
      " 0.01459376 0.0394196  0.00374584 0.00366822 0.00424091 0.00508478\n",
      " 0.00371126 0.0059118  0.12198315 0.0191726  0.17398717 0.07498058\n",
      " 0.01269208 0.01023589 0.03039391 0.11858904 0.00796357 0.0082979 ]\n"
     ]
    }
   ],
   "source": [
    "# Create a random forest classifier\n",
    "rfc = ensemble.RandomForestClassifier(n_estimators=100, random_state=0, n_jobs=-1)\n",
    "rfc.fit(X, y)\n",
    "# Train the classifier\n",
    "cross_val = cross_val_score(rfc, X, y, cv=10)\n",
    "print('Cross Validation Score: ', cross_val)\n",
    "print('Mean Cross Validation Score: ', cross_val.mean())\n",
    "print('\\n Feature Importances: ', rfc.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Scores:  [0.96551724 0.9137931  0.92982456 0.94736842 1.         0.98245614\n",
      " 0.98245614 0.98214286 0.94642857 0.94642857]\n",
      "Mean Cross Validation Score:  0.9596415607985481\n"
     ]
    }
   ],
   "source": [
    "# Create a random forest classifier with all variables with >0.5 feature importance. \n",
    "rfc = ensemble.RandomForestClassifier(n_estimators=100, random_state=0, n_jobs=-1)\n",
    "X_top_features = X[['radius_mean', 'smoothness_mean', 'compactness_mean', 'symmetry_se', 'radius_worst', 'texture_worst', 'smoothness_worst']]\n",
    "rfc.fit(X_top_features, y)\n",
    "# Train the classifier\n",
    "cross_val = cross_val_score(rfc, X_top_features, y, cv=10)\n",
    "print('Cross Validation Scores: ', cross_val)\n",
    "print('Mean Cross Validation Score: ', cross_val.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 162 candidates, totalling 1620 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    9.1s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:   39.1s\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done 792 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=-1)]: Done 1242 tasks      | elapsed:  4.1min\n",
      "[Parallel(n_jobs=-1)]: Done 1620 out of 1620 | elapsed:  6.3min finished\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py:813: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters for the best Random Forest Classifier:  RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "                       max_depth=50, max_features=2, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=4, min_samples_split=8,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=50,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=False, warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "rfc_gsc = GridSearchCV(\n",
    "        estimator=ensemble.RandomForestClassifier(),\n",
    "        param_grid={\n",
    "            'max_depth': [50, 100],\n",
    "            'max_features': [2, 3, 4],\n",
    "            'min_samples_leaf': [2, 3, 4],\n",
    "            'min_samples_split': [8, 10, 12],\n",
    "            'n_estimators': [50, 100, 500]\n",
    "        },\n",
    "        cv=10, scoring='accuracy', verbose=1, n_jobs=-1)\n",
    "\n",
    "rfc_gsc.fit(X_top_features, y)\n",
    "best_params = rfc_gsc.best_params_\n",
    "# svr_gsc.best_estimator_\n",
    "best_rfc = ensemble.RandomForestClassifier(max_depth=best_params['max_depth'], max_features=best_params[\"max_features\"],\n",
    "                                         min_samples_leaf=best_params[\"min_samples_leaf\"], min_samples_split=best_params[\"min_samples_split\"],\n",
    "                                         n_estimators=best_params['n_estimators'],verbose=False)\n",
    "\n",
    "print('Parameters for the best Random Forest Classifier: ', best_rfc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Scores:  [0.96551724 0.89655172 0.92982456 0.94736842 1.         0.96491228\n",
      " 0.94736842 0.96428571 0.92857143 0.96428571]\n",
      "Mean Cross Validation Score:  0.9508685506870623\n"
     ]
    }
   ],
   "source": [
    "rfc = ensemble.RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
    "                       max_depth=50, max_features=2, max_leaf_nodes=None,\n",
    "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "                       min_samples_leaf=4, min_samples_split=8,\n",
    "                       min_weight_fraction_leaf=0.0, n_estimators=50,\n",
    "                       n_jobs=None, oob_score=False, random_state=None,\n",
    "                       verbose=False, warm_start=False)\n",
    "rfc.fit(X_top_features, y)\n",
    "# Train the classifier\n",
    "cross_val = cross_val_score(rfc, X_top_features, y, cv=10)\n",
    "print('Cross Validation Scores: ', cross_val)\n",
    "print('Mean Cross Validation Score: ', cross_val.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a multi-layer perceptron neural network model to predict on a labeled dataset of your choosing. Compare this model to either a boosted tree or a random forest model and describe the relative tradeoffs between complexity and accuracy. Be sure to vary the hyperparameters of your MLP!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
